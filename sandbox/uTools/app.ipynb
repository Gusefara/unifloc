{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задания для рефакторинга\n",
    "\n",
    "1. Сделать все гибко\n",
    "\n",
    "2. Сделать все красиво\n",
    "\n",
    "3. Сделать все просто\n",
    "\n",
    "4. Сделать все логично\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кобзарь Олег, Хабибуллин Ринат, Буденный Семен, Адрианова Алла, Логинов Александр, Лемихов Александр\n",
    "# Обработчик данных \n",
    "\n",
    "В данной тетрадке собраны все средства для работы с данными (пре- и пост- процессор; генерация входных данных для модели, анализ рассчитанных значений, построение графиков)\n",
    "\n",
    "Большое количество кода вынесено в модуле - здесь в основном управление\n",
    "\n",
    "`well_name` - номер исследуемой скважины, например `1`\n",
    "\n",
    "Исходными данные лежат в папке  `data` в папках, соответствующим названиям скважин. Это данные\n",
    "1. Со станции управления (`data/well_name/well_name.csv`). Большое количество записей, которые нужно преобразовать в \"шахмоткоподобный\" вид для дальнейшей работы. Данные со СУ могут быть как высокочастотными (токи, напряжения), так и низкочастотными. \n",
    "2. С шахматки `data/well_name/Скв. well_name (01.07.2018-31.03.2019).xls`. Низкочастотные данные. \n",
    "3. C техрежима `data/tr/Техрежим, , февраль 2019.xls`. Какой насос спущен, ПЭД, на какую глубину. Эти данные постоянны на всем периоде расчета. В одном файлике один месяц и данные для всех скважин.\n",
    "\n",
    "\n",
    "\n",
    "## Общий workflow\n",
    "Здесь кратко, подробное описание будет над ячейками.\n",
    "1. Обработка исходных данных со СУ и приведение их в удобный формат. (init_edit)\n",
    "2. Считавание подготовленных ранее данных со СУ, шахматки, а затем генерации входных данных для модели, конкретно, адаптации модели скважины за выбранный период времени. (adaptation_input)\n",
    "3. Адаптация. Теперь можно открыть файл processor.py и в нем, выставив настройки и определив входные данные, запустить расчет скважину. После адаптации данные появится данные с калибровочными коэффициентами. (adaptation)\n",
    "4. Считывание рассчитанных значений адаптации, данных со СУ и шахматки. Генерации файлов для восстановления дебитов (restore_input)\n",
    "5. Восстановление. Работа в processor.py, где необходимо изменить метод расчета и указать на новые входные данные. (restore) \n",
    "6. Заключительный анализ: сведение результатов адаптации и восстановления; расчет различных метрик для оценки метода (тоже в папке restore)\n",
    "\n",
    "По идее, если данные уже сгенерированы, каждый пункт может повторяться многократно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт модулей. Некоторые функции и методы вынесены в отдельные `.py`\n",
    "* `preprocessor` - для обработки данных в и из модели\n",
    "* `processor` - для непосредственного запуска расчета адаптации или восстановления\n",
    "* `postprocessor` - для завершающего анализа сгенерированных данных. Определение метрик успешности модели, паттернов, событий, зависимостей.\n",
    "* `plotly_workflow` - для быстрого построения шаблонизированных графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_workflow.plotly_option as pltl_opt\n",
    "import plot_workflow.plotly_workflow as pltl_wf\n",
    "\n",
    "from preproc_p import workflow_cs_data\n",
    "from preproc_p import workflow_chess_data\n",
    "from preproc_p import preproc_tool\n",
    "from preproc_p import workflow_calc_data\n",
    "from preproc_p import workflow_tr_data\n",
    "from preproc_p import filtration\n",
    "from proc_p import processor as proc\n",
    "\n",
    "from ml import calibr_restore as calibr_restore\n",
    "from postproc_p import result_and_metrics as result_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общие настройки и флаги для работы. Указание номера скважины и название файла шахматки. Флаги для запуска тех или иных ячеек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_name = '1976'\n",
    "chess_file_name = 'Скв. 1976 (01.06.2019-30.11.2019).xls'\n",
    "tr_name = \"ТР Вынгаяхинское Январь 2020.csv\"\n",
    "# TODO убрать флаги\n",
    "read_initial_data = True\n",
    "plot_initial_data = True\n",
    "create_input_data = True\n",
    "auto_open_html = True\n",
    "multiprocessing_on = True #TODO может быть убрать флаги, как лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data_full_path = preproc_tool.find_full_path_by_pattern(os.getcwd(), \"*static_data.xlsx*\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение путей к данным. Создание метки времени к генерируемым папкам. (чтоб данные не перезаписывались)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "time_mark = '' #datetime.datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "path_to_data = current_path + \"\\\\data\\\\\"\n",
    "path_to_work_dir = current_path + \"\\\\data\\\\\" + well_name +  \"\\\\\"\n",
    "save_dir_name = 'init_edit'\n",
    "path_to_save = path_to_work_dir + save_dir_name + '\\\\'\n",
    "dirnames_list = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(path_to_data):\n",
    "    dirnames_list.extend(dirnames)\n",
    "    break\n",
    "print(dirnames_list)\n",
    "dynamic_data_full_path = path_to_save + well_name + \"_first_edit.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание интервалов, на которых будет вестить расчет. Их может быть несколько. Рекомендуется поставить малый период времени, выявить ошибки, а затем запускать на месяцы и годы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left_boundary = [datetime.datetime(2018,8,1), datetime.datetime(2018,11,29)]\n",
    "#right_boundary = [datetime.datetime(2018,11,5), datetime.datetime(2019,2,28)]\n",
    "#left_boundary = [datetime.datetime(2018,8,3), datetime.datetime(2018,11,29),   datetime.datetime(2019,2,19)]\n",
    "#right_boundary = [datetime.datetime(2018,11,6), datetime.datetime(2019,2,4),  datetime.datetime(2019,2,28)]\n",
    "#left_boundary = [datetime.datetime(2019,1,30)]\n",
    "#right_boundary = [datetime.datetime(2019,2,28)]\n",
    "left_boundary = [datetime.datetime(2018,6,27)]\n",
    "right_boundary = [datetime.datetime(2021,12,9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение функции которая все запустит в многопотоке и произведет из данного ноутбука адаптацию и восстановление. (Временный костыль - работает только здесь, в модуле не может)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_calculation(thread_option_list):\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(amount_of_threads) as p:\n",
    "            p.map(proc.calc,\n",
    "                  thread_option_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_names = preproc_tool.GlobalNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Обработка исходных данных\n",
    "Чтение исходных данных `well_name.csv` со СУ и преобразование их в удобный формат. Процесс небыстрый из-за несовершенства алгоритма форматирования и количества данных (около 1-1,5 млн. записей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "if read_initial_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + save_dir_name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с данными ГРАД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data_full_path = preproc_tool.find_full_path_by_pattern(os.getcwd(), f\"*{well_name} ВЧ.csv*\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data = workflow_cs_data.read_and_format_good_tm_data(well_name, grad_data_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data.to_csv(path_to_save + well_name + \"_first_edit_grad.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_grad = pltl_wf.create_traces_list_for_all_columms(grad_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "pltl_wf.plot_subplots(well_traces_grad,  path_to_save + well_name + \"_first_edit_grad.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с данными со СУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data_full_path = preproc_tool.find_full_path_by_pattern(os.getcwd(), f\"*{well_name}*\", 'флэш')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cs_data = workflow_cs_data.read_and_format_bad_tm_data(cs_data_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data.to_csv(path_to_save + well_name + \"_first_edit_cs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_cs = pltl_wf.create_traces_list_for_all_columms(cs_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "pltl_wf.plot_subplots(well_traces_cs,  path_to_save + well_name + \"_first_edit_cs.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с данными шахматки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data = workflow_chess_data.load_and_edit_chess_data(path_to_work_dir + chess_file_name,\n",
    "                                         '1d', without_changing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data.to_csv(path_to_save + well_name + \"_first_edit_chess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_chess = pltl_wf.create_traces_list_for_all_columms(chess_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "\n",
    "pltl_wf.plot_subplots(well_traces_chess,  path_to_save + well_name + \"_first_edit_chess.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков для нескольких интересующих параметров по исходным данных со СУ в `well_name__first_edit_report.html`. Процесс занимает около 3-5 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение данных в единый динамический DataFrame\n",
    "\n",
    "переименование нужных параметров, добавление меток источников данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data_edited = pd.read_csv(\n",
    "    path_to_save + well_name + \"_first_edit_grad.csv\", index_col='Время', parse_dates=True, dayfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data_edited = preproc_tool.rename_columns_by_dict(grad_data_edited)\n",
    "grad_data_edited = preproc_tool.solve_dimensions(grad_data_edited)\n",
    "grad_data_edited = preproc_tool.mark_df_columns(grad_data_edited, \"ГРАД\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data_edited = pd.read_csv(\n",
    "    path_to_save + well_name + \"_first_edit_cs.csv\", index_col='Время', parse_dates=True, dayfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data_edited = preproc_tool.rename_columns_by_dict(cs_data_edited)\n",
    "cs_data_edited = preproc_tool.solve_dimensions(cs_data_edited)\n",
    "cs_data_edited = preproc_tool.mark_df_columns(cs_data_edited, \"СУ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data_edited = pd.read_csv(\n",
    "    path_to_save + well_name + \"_first_edit_chess.csv\", index_col='Время', parse_dates=True, dayfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data_edited = preproc_tool.rename_columns_by_dict(chess_data_edited)\n",
    "chess_data_edited = preproc_tool.solve_dimensions(chess_data_edited)\n",
    "chess_data_edited = preproc_tool.mark_df_columns(chess_data_edited, \"ШТР\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = grad_data_edited.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = dynamic_data.join(cs_data_edited, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = dynamic_data.join(chess_data_edited, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = dynamic_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data.to_csv(path_to_save + well_name + \"_first_edit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_dynamic_data = pltl_wf.create_traces_list_for_all_columms(dynamic_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "\n",
    "pltl_wf.plot_subplots(well_traces_dynamic_data,  path_to_save + well_name + \"_first_edit.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Возможно надо сделать репорты для СУ и ШТР"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Вторичная обработка исходных данных для использования в модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного этапа уже нужные обработанные данные со станции управления.\n",
    "\n",
    "Чтение исходных данных со СУ (в уже подготовленных). Обработка этих данных - ресемпл, пометка названий столбцов с помощью `(СУ)`. Т.к. данные высокочастотные, осредним их по 3 часам - примерному времени замера дебита скважины на АГЗУ. Обработка будет отличаться в зависимости от того, какие данные вы генерируете - для адаптации выбрасываются интервалы без замеров дебитов, для восстановления - нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = pd.read_csv(dynamic_data_full_path, index_col = 'Время', parse_dates = True)\n",
    "prepared_dynamic_data = dynamic_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_tool.find_column_in_df_columns(dynamic_data, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_names.chosen_q_liq_m3day = global_names.q_liq_m3day + ' (ГРАД)'\n",
    "global_names.chosen_watercut_perc = 'Обв (ШТР)'\n",
    "global_names.chosen_gor_m3m3 = None\n",
    "\n",
    "global_names.chosen_p_buf_atm = global_names.p_lin_atm + ' (ГРАД)'\n",
    "global_names.chosen_p_intake_atm = global_names.p_intake_atm + ' (СУ)'\n",
    "global_names.chosen_t_intake_c =  global_names.t_intake_c + ' (СУ)'\n",
    "\n",
    "global_names.chosen_d_choke_mm = 'Dшт (ШТР)'\n",
    "\n",
    "global_names.chosen_cos_phi_d = global_names.cos_phi_d + ' (СУ)'\n",
    "global_names.chosen_i_a_motor_a = global_names.i_a_motor_a + ' (СУ)'\n",
    "global_names.chosen_u_motor_v = None\n",
    "global_names.chosen_motor_load_perc = global_names.motor_load_perc + ' (СУ)'\n",
    "global_names.chosen_freq_hz = global_names.freq_hz + ' (СУ)'\n",
    "global_names.chosen_active_power_kwt = global_names.active_power_kwt + ' (СУ)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_names.chosen_gor_m3m3 = global_names.gor_m3m3\n",
    "global_names.chosen_d_choke_mm =  global_names.d_choke_mm\n",
    "global_names.chosen_u_motor_v =  global_names.u_motor_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dynamic_data[global_names.q_liq_m3day] = prepared_dynamic_data[global_names.chosen_q_liq_m3day]\n",
    "prepared_dynamic_data[global_names.watercut_perc] = prepared_dynamic_data[global_names.chosen_watercut_perc]\n",
    "prepared_dynamic_data[global_names.gor_m3m3] = prepared_dynamic_data[global_names.chosen_p_intake_atm] * 0 + 105.5\n",
    "\n",
    "prepared_dynamic_data[global_names.p_buf_atm] = prepared_dynamic_data[global_names.chosen_p_buf_atm]\n",
    "prepared_dynamic_data[global_names.p_intake_atm] = prepared_dynamic_data[global_names.chosen_p_intake_atm]\n",
    "prepared_dynamic_data[global_names.t_intake_c] = prepared_dynamic_data[global_names.chosen_t_intake_c]\n",
    "\n",
    "prepared_dynamic_data[global_names.d_choke_mm] = prepared_dynamic_data[global_names.chosen_p_intake_atm] * 0 + 32\n",
    "\n",
    "prepared_dynamic_data[global_names.cos_phi_d] = prepared_dynamic_data[global_names.chosen_cos_phi_d]\n",
    "prepared_dynamic_data[global_names.i_a_motor_a] = prepared_dynamic_data[global_names.chosen_i_a_motor_a]\n",
    "prepared_dynamic_data[global_names.motor_load_perc] = prepared_dynamic_data[global_names.chosen_motor_load_perc]\n",
    "prepared_dynamic_data[global_names.freq_hz] = prepared_dynamic_data[global_names.chosen_freq_hz]\n",
    "prepared_dynamic_data[global_names.active_power_kwt] = prepared_dynamic_data[global_names.chosen_active_power_kwt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dynamic_data[global_names.u_motor_v] = prepared_dynamic_data[global_names.active_power_kwt] * 1000 / \\\n",
    "                                                prepared_dynamic_data[global_names.i_a_motor_a + ' (СУ)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тут должна быть фильтрация, удаление мусора из колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(prepared_dynamic_data, report_type = 'second_edit_data')\n",
    "pltl_wf.create_report_html(prepared_dynamic_data, all_banches, path_to_save + well_name + \"_second_edit_report.html\",  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dynamic_data.to_csv(path_to_save + well_name + \"_second_edit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_prepared_dynamic_data = pltl_wf.create_traces_list_for_all_columms(prepared_dynamic_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "\n",
    "pltl_wf.plot_subplots(well_traces_prepared_dynamic_data,  path_to_save + well_name + \"_second_edit.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тут общий ресемпл (возможно нет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Подготовка данных к адаптации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_resamle = '1h'\n",
    "input_data_dir_name = 'adapt_input_' + time_mark\n",
    "path_to_input_data = path_to_work_dir + input_data_dir_name + '\\\\'\n",
    "plot_file_path = path_to_input_data + well_name\n",
    "if create_input_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + input_data_dir_name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dynamic_data = pd.read_csv(path_to_save + well_name + \"_second_edit.csv\", index_col = 'Время', parse_dates = True, dayfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data = prepared_dynamic_data.resample(time_to_resamle).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data[global_names.watercut_perc] = adapt_input_dynamic_data[global_names.watercut_perc].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data = adapt_input_dynamic_data.dropna(subset = [global_names.q_liq_m3day])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data = adapt_input_dynamic_data.dropna(subset = [global_names.p_intake_atm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут не должно быть фильтрации, но должен быть чек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data = filtration.get_filtred_by_sigma(adapt_input_dynamic_data, global_names.q_liq_m3day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(adapt_input_dynamic_data, report_type = 'second_edit_data')\n",
    "pltl_wf.create_report_html(adapt_input_dynamic_data, all_banches, plot_file_path + \"_adapt_input_report.html\",  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_adapt_input_dynamic_data = pltl_wf.create_traces_list_for_all_columms(adapt_input_dynamic_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "pltl_wf.plot_subplots(well_traces_adapt_input_dynamic_data,  plot_file_path + \"_adapt_input.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data.to_csv(path_to_input_data + well_name + '_adapt_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data[global_names.active_power_kwt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация входных данных для адаптации. Сведение данных с шахматки и со СУ. Создание папки с названием `adapt_input_` и временной пометкой и помещение в нее:\n",
    "* сгенерированных входных данных для модели `well_name_adapt_input.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все входные данные на графике `well_name_adapt_input.html` в той же папке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение кривых в отчете только для тех данных, которые будут использоваться в модели в `well_name_adapt_input_report.html` в той же папке в стандартном виде. Можно настроить, какие данные выводить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Адаптация\n",
    "Нужно, используя сгенерированные данные `well_name_adapt_input` получить значения коэффициентов калибровок по напору и мощности с помощью `processor.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка к параллельному расчету.\n",
    "\n",
    "В проекте UniflocVBA нужно вручную размножить надстройки до нужного количества потоков - каждая надстройка будет работать параллельно и рассчитывать определенную часть общих данных. \n",
    "\n",
    "По умолчанию выставлено 4 потока на 4 надстройках `UniflocVBA_7.xlam`, `UniflocVBA_7_1.xlam`, `UniflocVBA_7_2.xlam`, `UniflocVBA_7_3.xlam`. При желании можно добавить еще, не забыв изменить также номера потоков и их общее количество.\n",
    "\n",
    "Группировка информации о потоках в единый список `thread_option_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка многопоточности\n",
    "amount_of_threads = 12\n",
    "dir_name_with_input_data = 'adapt_input_'\n",
    "\n",
    "thread_option_list =proc.create_thread_list(well_name, dir_name_with_input_data, static_data_full_path,\n",
    "                       amount_of_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск процесса адаптации - получения калибровок. Процесс может быть долгим - в среднем расчет идет медленнее, чем при восстановлении дебитов. \n",
    "\n",
    "Рассчет 1 месяца в среднем занимает около 15-20 минут.\n",
    "\n",
    "Стоит отметить, что для аварийного выхода нужно вручную закрыть надстройки Excel (окна, которые открыты и в них ведется работа). После закрытия всех четырех процесс остановится и возникнет ошибка, контроль над jupyter notebook вернется и можно будет работать.\n",
    "\n",
    "Поэтому для тщательной отладки `processor.py` рекомендуется запускать отдельно (лучше через PyCharm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_calculation(thread_option_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Загрузка и анализ адаптации\n",
    "После успешной адаптации нужно проанализировать ее корректность, построив графики. Для этого нужно указать директории с \n",
    "* результатами адапатации - `adaptation`  \n",
    "* входными данными для адаптации - `adapt_input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_with_input_data = 'adapt_input_' + '\\\\'\n",
    "input_data_file_name = well_name + '_adapt_input'\n",
    "dir_name_with_calculated_data = 'adaptation_' + '\\\\'\n",
    "calculated_data_file_name = well_name + '_adapt_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если расчет проводился в многопоточном варианте, то загрузка будет отличаться. В папке с расчетами `adaptation` в сабдиректории `multiprocessing` будут результаты по частям в разных файликах, поэтому их нужно собрать в один файлик и поместить на уровень выше в `adaptation`. Если расчет был без использования многопоточности, этот шаг можно пропустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multiprocessing_on == True:\n",
    "    first_result_data = preproc_tool.combine_multiprocessing_result(path_to_work_dir, dir_name_with_calculated_data)\n",
    "    first_result_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + calculated_data_file_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных адаптации после расчета - в папке `adaptation_time_mark`  файл `well_name_adapt_1.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data = workflow_calc_data.load_calculated_data_from_csv(path_to_work_dir + dir_name_with_calculated_data +\n",
    "                                                calculated_data_file_name +  '.csv', \"ADAPT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение входных данных для адаптации из папки `adaptation_input` и объединение данных адатации и входных данных для нее.\n",
    "Сохранение всех данных в папке `adaptation_time_mark` с названием `well_name_calc_and_input.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(path_to_work_dir + dir_name_with_input_data + input_data_file_name +  '.csv',index_col = 'Время', parse_dates = True)\n",
    "all_data = input_data.join(calculated_data, how = 'outer')\n",
    "all_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков для данных адаптации в папке  `adaptation`\n",
    "\n",
    "Все данные (входные и результаты) на одном графике `well_name_calc_and_input.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_data_traces = pltl_wf.create_traces_list_for_all_columms(all_data, 'lines+markers', use_gl = True)\n",
    "plot_file_path = path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.html'\n",
    "pltl_wf.plot_subplots(adapt_data_traces, plot_file_path, True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание отчета - набор нужных графиков для быстрой оценки результатов адаптации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(report_type = 'adaptation')\n",
    "\n",
    "pltl_wf.create_report_html(all_data, all_banches, path_to_work_dir + dir_name_with_calculated_data + \n",
    "                      well_name + '_adapt_report.html',  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Генерации данных для прогнозирования дебитов с помощью ML\n",
    "Работа с калибровками для восстановления дебитов. Для преобразования их выделим в отдельный DataFrame. Будем интерполировать, выкалавать точки, либо еще что-нибудь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_data = calculated_data[['К. калибровки по напору - множитель (Модель)',\n",
    "                               'К. калибровки по мощности - множитель (Модель)']]\n",
    "calibr_data = preproc_tool.mark_df_columns(calibr_data, 'Подготовленные')\n",
    "#calibr_data = calibr_data.resample('3h').mean()\n",
    "#calibr_data = calibr_data.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_out_lol, f_out_lol = calibr_restore.restore_calibr_via_ridge(all_data, calibr_data, use_80_20 = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_resamle = '1h'\n",
    "created_input_data_type = 0 # костыль для 252 и 693 скважины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO учесть вариант, при котором калибровки линейно интерполируются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_data_cs = workflow_cs_data.load_and_edit_cs_data(cs_data_filename,created_input_data_type,\n",
    "                                       time_to_resamle\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data = workflow_chess_data.load_and_edit_chess_data(path_to_work_dir + chess_file_name,\n",
    "                                     time_to_resamle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прозведем фильтрацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_data_cs = filtration.get_filtred_by_sigma(edited_data_cs) #TODO добавить сюда фильтрацию по времени замера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = preproc_tool.make_gaps_and_interpolate(calibr_data)\n",
    "calibr_data = result.copy()\n",
    "#all_data = all_data.join(calibr_data, how = 'inner')\n",
    "#created_input_data = all_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вставляем предсказания машины\n",
    "calibr_data['К. калибровки по мощности - множитель (Модель) (Подготовленные)'] = p_out_lol\n",
    "calibr_data['К. калибровки по напору - множитель (Модель) (Подготовленные)'] = f_out_lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вставим исходные калибровки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_data['К. калибровки по мощности - множитель (Модель) (При адаптации)'] = calculated_data['К. калибровки по мощности - множитель (Модель)']\n",
    "calibr_data['К. калибровки по напору - множитель (Модель) (При адаптации)'] =  calculated_data['К. калибровки по напору - множитель (Модель)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не считать все подряд, будем использовать только интервалы для прогноза/адаптации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_data = calibr_data[calibr_data['К. калибровки по мощности - множитель (Модель) (Подготовленные)']!=\n",
    "                          calculated_data['К. калибровки по мощности - множитель (Модель)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем данные со СУ и шахматки и обработаем их, для генерации входных данных модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация входных данных для модели для восстановления дебитов в папку `restore_input_time_mark`\n",
    "* `well_name_restore_input.csv` - входные данных с калибровками (увеличили частоту дискретизации или выкололи точки)\n",
    "* `well_name_restore_input.html` - все входные данные на одном графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir_name = 'restore_input_' + time_mark\n",
    "path_to_input_data = path_to_work_dir + input_data_dir_name + '\\\\'\n",
    "if create_input_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + input_data_dir_name)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_input_data = edited_data_cs.join(chess_data, how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_input_data = created_input_data.join(calibr_data, how ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_input_data = preproc_tool.cut_df(created_input_data, left_boundary, right_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_input_data.to_csv(path_to_input_data + well_name + '_restore_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_path = path_to_input_data + well_name + '_restore_input.html'\n",
    "input_data_traces = pltl_wf.create_traces_list_for_all_columms(created_input_data, 'lines+markers', use_gl = True)\n",
    "pltl_wf.plot_subplots(input_data_traces, plot_file_path, True,  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков в отчетной форме "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(created_input_data, report_type = 'restore_input')\n",
    "\n",
    "pltl_wf.create_report_html(created_input_data, all_banches, path_to_input_data  + \n",
    "                      well_name + '_restore_input_report.html',  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Восстановление дебитов.\n",
    "Нужно, используя сгенерированные данные `well_name_restore_input` восстановить дебиты с помощью `postprocessor.py`\n",
    "Для этого активировать флаги\n",
    "* vfm_calc_option = True\n",
    "* restore_q_liq_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка к параллельному расчету.\n",
    "\n",
    "В проекте UniflocVBA нужно вручную размножить надстройки до нужного количества потоков - каждая надстройка будет работать параллельно и рассчитывать определенную часть общих данных. \n",
    "\n",
    "По умолчанию выставлено 4 потока на 4 надстройках `UniflocVBA_7.xlam`, `UniflocVBA_7_1.xlam`, `UniflocVBA_7_2.xlam`, `UniflocVBA_7_3.xlam`. При желании можно добавить еще, не забыв изменить также номера потоков и их общее количество.\n",
    "\n",
    "Группировка информации о потоках в единый список `thread_option_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка многопоточности\n",
    "\n",
    "amount_of_threads = 12\n",
    "dir_name_with_input_data = 'restore_input_'\n",
    "\n",
    "thread_option_list =proc.create_thread_list(well_name, dir_name_with_input_data, static_data_full_path,\n",
    "                       amount_of_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск процесса восстановления дебитов. Процесс может быть долгим - в среднем расчет восстановления дебитов идет быстрее, чем при адаптации (получении калибровок). \n",
    "\n",
    "Рассчет 1 месяца в среднем занимает около 10-15 минут.\n",
    "\n",
    "Стоит отметить, что для аварийного выхода нужно вручную закрыть надстройки Excel (окна, которые открыты и в них ведется работа). После закрытия всех четырех процесс остановится и возникнет ошибка, контроль над jupyter notebook вернется и можно будет работать.\n",
    "\n",
    "Поэтому для тщательной отладки processor.py рекомендуется его запускать отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "run_calculation(thread_option_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты расчета появятся в `well_name/restore_time_mark/multiprocessing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Работа с данными после восстановления дебитов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Первичная обработка результатов восстановления\n",
    "Обозначим директории с результатами восстановления дебитов и входными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_with_input_data = 'restore_input_' + '\\\\'\n",
    "input_data_file_name = well_name +'_restore_input'\n",
    "dir_name_with_calculated_data = 'restore_' + '\\\\'\n",
    "calculated_data_file_name = well_name +'_restore_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение данных при запуске расчета в многопотоке. Если расчет проводился без многопоточности, этот шаг можно пропустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multiprocessing_on == True:\n",
    "    first_result_data = preproc_tool.combine_multiprocessing_result(path_to_work_dir, dir_name_with_calculated_data)\n",
    "    first_result_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + calculated_data_file_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных после восстановления дебитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data = workflow_calc_data.load_calculated_data_from_csv(path_to_work_dir + dir_name_with_calculated_data +\n",
    "                                                calculated_data_file_name +  '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение входных и выходных данным модели. Сохранение результатов в `well_name_calc_and_input.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(path_to_work_dir + dir_name_with_input_data + input_data_file_name +  '.csv', parse_dates = True, index_col = 'Время')\n",
    "all_data = input_data.join(calculated_data, how = 'outer')\n",
    "all_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков восстановления дебитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_traces = pltl_wf.create_traces_list_for_all_columms(all_data, 'lines+markers', use_gl = True)\n",
    "plot_file_path = path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.html'\n",
    "pltl_wf.plot_subplots(input_data_traces, plot_file_path, True,  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Сведение данных адаптации и восстановления\n",
    "Использование файлов типа `calc_and_input` в папках с адаптацией и восстновлением для формирования общего отчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_adapt_dir = 'adaptation_' + '\\\\'\n",
    "path_to_restore_dir = 'restore_' + '\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка и слияние данных адаптации и восстановления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_data_with_input = pd.read_csv(path_to_work_dir + path_to_adapt_dir + well_name + '_calc_and_input' + '.csv' , parse_dates = True, index_col = 'Время')\n",
    "adapt_data_with_input = preproc_tool.mark_df_columns(adapt_data_with_input, 'ADAPT')\n",
    "restore_data_with_input = pd.read_csv(path_to_work_dir + path_to_restore_dir + well_name + '_calc_and_input' + '.csv' , parse_dates = True, index_col = 'Время')\n",
    "restore_data_with_input = preproc_tool.mark_df_columns(restore_data_with_input, 'RESTORE')\n",
    "overall_data = adapt_data_with_input.join(restore_data_with_input, how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение дебитов методом линейной интерполяции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_liq = overall_data[['Объемный дебит жидкости (СУ) (ADAPT)', 'Активная мощность (СУ) (ADAPT)']]\n",
    "result = preproc_tool.make_gaps_and_interpolate(q_liq)\n",
    "result = preproc_tool.mark_df_columns(result, 'INTERP')\n",
    "overall_data = overall_data.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заключительная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data = result_and_metrics.final_edit_overall_data(overall_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка вывода в отчет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(overall_data, report_type = 'overall_result')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание сводного отчета `well_name_adapt_and_restore_report.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data['Qж ТМ (Ш) (ADAPT)'] = overall_data['Линейное давление (СУ) (ADAPT)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_path = path_to_work_dir + path_to_restore_dir + well_name + '_adapt_and_restore_report' +  '.html'\n",
    "pltl_wf.create_report_html(overall_data, all_banches, plot_file_path,  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет различных метрик для модели и сохранение их в текстовый файл `well_name_adapt_and_restore_metrics_report.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_calc_metrics, interp_calc_metrics = result_and_metrics.calc_calibr_interp_metrics(overall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_text_file_path = path_to_work_dir + path_to_restore_dir + well_name + '_adapt_and_restore_metrics_report' +  '.txt'\n",
    "text_file = open(metrics_text_file_path, \"w\")\n",
    "text_file.write(calibr_calc_metrics + '\\n' + interp_calc_metrics)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Построение тепловой карты, характеристик и обезразмеренных величин\n",
    "Пару дополнительных функций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение данных с техрежима для данной скважины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_file_full_path = os.getcwd() + '\\\\data\\\\tr\\\\' + tr_name\n",
    "pvt_file_full_path = os.getcwd() + '\\\\data\\\\tr\\\\' + pvt_name\n",
    "\n",
    "tr_data = workflow_tr_data.read_tr_and_get_data(tr_file_full_path, well_name)\n",
    "tr_data = workflow_tr_data.read_pvt_file_and_fill_tr_data(pvt_file_full_path, well_name, tr_data)\n",
    "tr_data_df = pd.DataFrame({'Параметры скважины с ТР': list(tr_data.__dict__.values())})\n",
    "tr_data_df.index = list(tr_data.__dict__.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение метрик и данных по скважине в единый DataFrame (вместе с линейной интерполяцией). Сохранение в `_adapt_restore_metrics_tr_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_metrics = result_and_metrics.calc_calibr_interp_metrics(overall_data, return_df = True)\n",
    "\n",
    "overall_metrics['ЭЦН'] = [tr_data.esp_name_str, tr_data.esp_name_str]\n",
    "overall_metrics['ПЭД'] = [tr_data.motor_name_str, tr_data.motor_name_str]\n",
    "overall_metrics['Кол-во точек (ADAPT)'] = [len(overall_data['К. калибровки по напору - множитель (Модель) (ADAPT)']), \n",
    "                                           len(overall_data['К. калибровки по напору - множитель (Модель) (ADAPT)'])]\n",
    "overall_metrics['MAE/Q ж, м3/сут (Модель) (ADAPT) mean, %'] = overall_metrics['Mean absolute error'] / overall_metrics['Q ж, м3/сут (Модель) (ADAPT) mean'] * 100\n",
    "overall_metrics.index = [well_name + ' (CALIBR)' , well_name + ' (INTERP)']\n",
    "overall_metrics.to_csv(path_to_work_dir + path_to_restore_dir + well_name + '_adapt_restore_metrics_tr_report' +  '.csv')\n",
    "overall_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вызов UniflocVBA и построение напорных характеристик (по воде) данного насоса, создание общего отчета с пометкой `_dimless_pump_heatmap_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_esp_nom_m3day = tr_data.esp_nom_rate_m3day\n",
    "head_esp_nom_m = tr_data.esp_nom_head_m\n",
    "\n",
    "import unifloc_vba.description_generated.python_api as python_api\n",
    "path_to_addin = os.getcwd()\n",
    "path_to_addin = path_to_addin.replace('unifloc\\\\sandbox\\\\uTools', 'unifloc_vba\\\\UniflocVBA_7.xlam')\n",
    "UniflocVBA = python_api.API(path_to_addin)\n",
    "esp_traces = pltl_wf.create_esp_traces(UniflocVBA, q_esp_nom_m3day, head_esp_nom_m)\n",
    "overall_data_dimensionless = result_and_metrics.make_dimensionless_df(overall_data)\n",
    "filename = path_to_work_dir + path_to_restore_dir + well_name + '_dimless_pump_heatmap_report' + '.html'\n",
    "pltl_wf.create_overall_report(overall_data, overall_data_dimensionless, esp_traces, filename,  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конец"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
