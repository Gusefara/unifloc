{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кобзарь О.С. Хабибуллин Р.А.\n",
    "# Обработчик данных \n",
    "\n",
    "В данной тетрадке собраны все средства для работы с данными (пре- и пост- процессор; генерация входных данных для модели, анализ рассчитанных значений, построение графиков)\n",
    "\n",
    "Большое количество кода вынесено в модуле - здесь в основном управление\n",
    "\n",
    "`well_name` - номер исследуемой скважины, например `1`\n",
    "\n",
    "Исходными данные лежат в папке  `data` в папках, соответствующим названиям скважин. Это данные\n",
    "1. Со станции управления (`data/well_name/well_name.csv`). Большое количество записей, которые нужно преобразовать в \"шахмоткоподобный\" вид для дальнейшей работы. Данные со СУ могут быть как высокочастотными (токи, напряжения), так и низкочастотными. \n",
    "2. С шахматки `data/well_name/Скв. well_name (01.07.2018-31.03.2019).xls`. Низкочастотные данные. \n",
    "3. C техрежима `data/tr/Техрежим, , февраль 2019.xls`. Какой насос спущен, ПЭД, на какую глубину. Эти данные постоянны на всем периоде расчета. В одном файлике один месяц и данные для всех скважин.\n",
    "\n",
    "\n",
    "\n",
    "## Общий workflow\n",
    "Здесь кратко, подробное описание будет над ячейками.\n",
    "1. Обработка исходных данных со СУ и приведение их в удобный формат. (init_edit)\n",
    "2. Считавание подготовленных ранее данных со СУ, шахматки, а затем генерации входных данных для модели, конкретно, адаптации модели скважины за выбранный период времени. (adaptation_input)\n",
    "3. Адаптация. Теперь можно открыть файл processor.py и в нем, выставив настройки и определив входные данные, запустить расчет скважину. После адаптации данные появится данные с калибровочными коэффициентами. (adaptation)\n",
    "4. Считывание рассчитанных значений адаптации, данных со СУ и шахматки. Генерации файлов для восстановления дебитов (restore_input)\n",
    "5. Восстановление. Работа в processor.py, где необходимо изменить метод расчета и указать на новые входные данные. (restore) \n",
    "6. Заключительный анализ: сведение результатов адаптации и восстановления; расчет различных метрик для оценки метода (тоже в папке restore)\n",
    "\n",
    "По идее, если данные уже сгенерированы, каждый пункт может повторяться многократно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт модулей. Некоторые функции и методы вынесены в отдельные `.py`\n",
    "* `preprocessor` - для обработки данных в и из модели\n",
    "* `processor` - для непосредственного запуска расчета адаптации или восстановления\n",
    "* `postprocessor` - для завершающего анализа сгенерированных данных. Определение метрик успешности модели, паттернов, событий, зависимостей.\n",
    "* `plotly_workflow` - для быстрого построения шаблонизированных графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import preprocessor as prep\n",
    "import postprocessor as postp\n",
    "import pandas as pd\n",
    "import unifloc.uniflocpy.uTools.plotly_workflow as pw\n",
    "import datetime\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общие настройки и флаги для работы. Указание номера скважины и название файла шахматки. Флаги для запуска тех или иных ячеек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_name = '1354'\n",
    "chess_file_name = 'Скв. ' + well_name + ' (01.07.2018-31.03.2019).xls'\n",
    "\n",
    "# TODO убрать флаги\n",
    "read_initial_data = True\n",
    "plot_initial_data = True\n",
    "create_input_data = True\n",
    "multiprocessing_on = True #TODO может быть убрать флаги, как лучше?\n",
    "created_input_data_type = 0 # 0 - adaptation input, 1 - restore input with calibation coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение путей к данным. Создание метки времени к генерируемым папкам. (чтоб данные не перезаписывались)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "time_mark = datetime.datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "path_to_data = current_path + \"\\\\data\\\\\"\n",
    "path_to_work_dir = current_path + \"\\\\data\\\\\" + well_name +  \"\\\\\"\n",
    "save_dir_name = 'init_edit'\n",
    "path_to_save = path_to_work_dir + save_dir_name + '\\\\'\n",
    "dirnames_list = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(path_to_data):\n",
    "    dirnames_list.extend(dirnames)\n",
    "    break\n",
    "print(dirnames_list)\n",
    "cs_data_filename = path_to_save + well_name + \"_first_edit.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание интервалов, на которых будет вестить расчет. Их может быть несколько. Рекомендуется поставить малый период времени, выявить ошибки, а затем запускать на месяцы и годы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_boundary = [datetime.datetime(2019,1,1)]#, datetime.datetime(2018,11,29)]\n",
    "right_boundary = [datetime.datetime(2019,2,28)]#, datetime.datetime(2019,2,28)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Обработка исходных данных\n",
    "Чтение исходных данных `well_name.csv` со СУ и преобразование их в удобный формат. Процесс небыстрый из-за несовершенства алгоритма форматирования и количества данных (около 1-1,5 млн. записей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if read_initial_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + save_dir_name)\n",
    "    except:\n",
    "        pass\n",
    "    data_file_path = path_to_work_dir + well_name + \".csv\"\n",
    "    well_data = pd.read_csv(data_file_path,sep=';', header=None)\n",
    "    well_data = prep.initial_editing(well_data, well_name)\n",
    "    well_data = prep.create_edited_df(well_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение обработанных данных со СУ в папку `init_edit`\n",
    "\n",
    "Процесс может быть долгим - 3 минуты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#TODO использовать библиотеку modin вместо pandas\n",
    "well_data.to_csv(path_to_save + well_name + \"_first_edit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков для нескольких интересующих параметров по исходным данных со СУ в `well_name__first_edit_report.html`. Процесс занимает около 3-5 минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "well_data['ГФ, м3/м3'] = well_data['Объемный дебит газа'] / well_data['Объемный дебит нефти']\n",
    "qliq = {'Объемный дебит жидкости':['Объемный дебит жидкости']}\n",
    "gor = {'ГФ, м3/м3':['ГФ, м3/м3']}\n",
    "wc = {'Процент обводненности':['Процент обводненности']}\n",
    "pressure_intake = {'Давление на приеме': ['Давление на приеме насоса (пласт. жидкость)']}\n",
    "pressure_wh = {'Линейное давление': ['Линейное давление']}\n",
    "temp_intake = {'Температура на приеме насоса': ['Температура на приеме насоса (пласт. жидкость)']}\n",
    "frequencies = {'Выходная частота ПЧ':\n",
    "               ['Выходная частота ПЧ']}\n",
    "load = {'Загрузка двигателя': ['Загрузка двигателя']}\n",
    "power = {'Активная мощность':['Активная мощность']}\n",
    "voltage = {'Напряжение на выходе ТМПН':['Напряжение на выходе ТМПН']}\n",
    "cos = {'Коэффициент мощности':['Коэффициент мощности']}\n",
    "time = {'Время замеров':['Время замера фактическое','Время замера плановое']}\n",
    "current =  {'Ток фазы А':['Ток фазы А']}\n",
    "all_banches = [qliq,gor, wc, time, pressure_intake, pressure_wh, \n",
    "               temp_intake, frequencies, load,power, voltage,cos,current]\n",
    "\n",
    "pw.create_report_html(well_data, all_banches, path_to_save + well_name + \"_first_edit_report.html\")\n",
    "del well_data['ГФ, м3/м3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение всех исходных данных со станции управления через `plotly`. Сохранение в ту же папку. Процесс долгий опять же из-за большого количества точек. Ориентировочное время - 10 минут - можно за чаем сходить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time  #TODO слишком долго: либо убрать, либо заменить на report\n",
    "#plot_file_path = path_to_save + well_name + '_init_sp.html'\n",
    "#well_data_traces = pw.create_traces_list_for_all_columms(well_data, 'lines+markers', use_gl = True)\n",
    "#pw.plot_subplots(well_data_traces, plot_file_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение исходных данных с шахматки в `well_name_chess_report.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chess_data = prep.load_and_edit_chess_data(path_to_work_dir + chess_file_name,\n",
    "                                     '1d', without_changing = True)\n",
    "qliq = {'Qж ТМ':['Qж ТМ']}\n",
    "wc = {'Обв ТМ':['Обв ТМ']}\n",
    "pressure_intake = {'Рэцн ТМ': ['Рэцн ТМ']}\n",
    "pressure_wh = {'Рлин ТМ': ['Рлин ТМ']}\n",
    "pressure_buf = {'Р буферное': ['Рбуф ТМ', 'Рбуф']}\n",
    "temp_intake = {'Темп. ж. ТМ ': ['Темп. ж. ТМ']}\n",
    "frequencies = {'F вращ ТМ':\n",
    "               ['F вращ ТМ']}\n",
    "load = {'Загр. ПЭД (ТМ)': ['Загр. ПЭД (ТМ)']}\n",
    "cos = {'Cos ф (ТМ)':['Cos ф (ТМ)']}\n",
    "choke = {'Dшт':['Dшт']}\n",
    "current =  {'I A ТМ':['I A ТМ']}\n",
    "all_banches = [qliq, wc, pressure_intake, pressure_wh, pressure_buf,\n",
    "               temp_intake, frequencies, load,cos,choke, current]\n",
    "\n",
    "pw.create_report_html(chess_data, all_banches, path_to_save + well_name + \"_chess_report.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом этапе в папке init_edit окажутся\n",
    "1. well_name_init_edit.csv - данные с шахматки, которые будут подгружаться для адаптации и восстановления\n",
    "2. well_name_init_sp.html - график для исходных данных\n",
    "3.  well_name_init_edit_report.html - график для выбранных исходных данных\n",
    "\n",
    "Перейдем к следующему этапу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Генерация входных данных для адаптации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного этапа уже нужные обработанные данные со станции управления.\n",
    "\n",
    "Чтение исходных данных со СУ (в уже подготовленных). Обработка этих данных - ресемпл, пометка названий столбцов с помощью `(СУ)`. Т.к. данные высокочастотные, осредним их по 3 часам - примерному времени замера дебита скважины на АГЗУ. Обработка будет отличаться в зависимости от того, какие данные вы генерируете - для адаптации выбрасываются интервалы без замеров дебитов, для восстановления - нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_resamle = '3h'\n",
    "created_input_data_type = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "edited_data_cs = prep.load_and_edit_cs_data(cs_data_filename,\n",
    "                                       time_to_resamle, \n",
    "                                       created_input_data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение данных с шахматки. Осреднение и протяжка параметров. Пометка названий столбцов маркером `(Ш)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chess_data = prep.load_and_edit_chess_data(path_to_work_dir + chess_file_name,\n",
    "                                     time_to_resamle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация входных данных для адаптации. Сведение данных с шахматки и со СУ. Создание папки с названием `adapt_input_` и временной пометкой и помещение в нее:\n",
    "* сгенерированных входных данных для модели `well_name_adapt_input.csv`\n",
    "* всех входных данных на графике `well_name_adapt_input.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir_name = 'adapt_input_' + time_mark\n",
    "path_to_input_data = path_to_work_dir + input_data_dir_name + '\\\\'\n",
    "if create_input_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + input_data_dir_name)\n",
    "    except:\n",
    "        pass\n",
    "created_input_data = edited_data_cs.join(chess_data, how = 'outer')\n",
    "created_input_data = created_input_data.dropna(subset = ['Объемный дебит жидкости (СУ)'])\n",
    "created_input_data = prep.cut_df(created_input_data, left_boundary, right_boundary)\n",
    "plot_file_path = path_to_input_data + well_name + '_adapt_input.html'\n",
    "input_data_traces = pw.create_traces_list_for_all_columms(created_input_data, 'lines+markers', use_gl = True)\n",
    "pw.plot_subplots(input_data_traces, plot_file_path, True)\n",
    "\n",
    "created_input_data.to_csv(path_to_input_data + well_name + '_adapt_input.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение кривых в отчете только для тех данных, которые будут использоваться в модели в `well_name_adapt_input_report.html` в той же папке в стандартном виде. Можно настроить, какие данные выводить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_input_data['Линейное давление (СУ)'] =  created_input_data['Линейное давление (СУ)'] * 10\n",
    "qliq = {'Объемный дебит жидкости (СУ)':['Объемный дебит жидкости (СУ)']}\n",
    "pressure_intake = {'Давление на приеме': ['Давление на приеме насоса (пласт. жидкость) (СУ)']}\n",
    "pressure_wh = {'Рлин ТМ (Ш)': ['Рлин ТМ (Ш)', 'Линейное давление (СУ)']}\n",
    "pressure_bf = {'Рбуф (Ш)': ['Рбуф (Ш)']}\n",
    "temp_intake = {'Температура на приеме насоса (пласт. жидкость) (СУ)': ['Температура на приеме насоса (пласт. жидкость) (СУ)']}\n",
    "frequencies = {'Частота, Гц':\n",
    "               ['F вращ ТМ (Ш)', 'Выходная частота ПЧ (СУ)']}\n",
    "choke = {'Размер штуцера, мм': ['Dшт (Ш)']}\n",
    "power = {'Активная мощность (СУ)':['Активная мощность (СУ)']}\n",
    "voltage = {'Напряжение на выходе ТМПН (СУ)':['Напряжение на выходе ТМПН (СУ)']}\n",
    "cos = {'Коэффициент мощности (СУ)':['Коэффициент мощности (СУ)']}\n",
    "gor = {'ГФ (СУ)':['ГФ (СУ)']}\n",
    "wc = {'Процент обводненности (СУ)':['Процент обводненности (СУ)']}\n",
    "all_banches = [qliq, gor,wc, pressure_intake, pressure_wh, pressure_bf,\n",
    "               temp_intake, frequencies, choke,power,voltage,cos]\n",
    "\n",
    "pw.create_report_html(created_input_data, all_banches, path_to_input_data + well_name + '_adapt_input_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Адаптация\n",
    "\n",
    "Нужно запустить модуль `processor.py` и начать в нем адаптацию, используя `well_name_adapt_input.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Генерация данных для восстановления дебитов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Загрузка и анализ адаптации\n",
    "После успешной адаптации нужно проанализировать ее корректность, построив графики. Для этого нужно указать директории с \n",
    "* результатами адапатации - `adaptation_time_mark`  \n",
    "* входными данными для адаптации - `adaptation_input_time_mark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_with_input_data = 'adapt_input_2019_11_16_17_36_10' + '\\\\'\n",
    "input_data_file_name = well_name + '_adapt_input'\n",
    "dir_name_with_calculated_data = 'adaptation_2019_11_16_17_40_20' + '\\\\'\n",
    "calculated_data_file_name = well_name + '_adapt_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если расчет проводился в многопоточном варианте, то загрузка будет отличаться. В папке с расчетами `adaptation` в сабдиректории `multiprocessing` будут результаты по частям в разных файликах, поэтому их нужно собрать в один файлик и поместить на уровень выше в `adaptation`. Если расчет был без использования многопоточности, этот шаг можно пропустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multiprocessing_on == True:\n",
    "    filenames_list = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path_to_work_dir + dir_name_with_calculated_data + 'multiprocessing\\\\'):\n",
    "        filenames_list.extend(filenames)\n",
    "        break\n",
    "    print(filenames_list)\n",
    "    for i,j in enumerate(filenames_list):\n",
    "        if i == 0:\n",
    "            first_result_data = pd.read_csv(path_to_work_dir + dir_name_with_calculated_data + 'multiprocessing\\\\' + j , parse_dates = True, index_col = 'Время')\n",
    "        else:\n",
    "            another_result_data = pd.read_csv(path_to_work_dir + dir_name_with_calculated_data + 'multiprocessing\\\\' + j , parse_dates = True, index_col = 'Время')\n",
    "            first_result_data = first_result_data.append(another_result_data, sort = True)\n",
    "            del first_result_data['d']\n",
    "            first_result_data = first_result_data.dropna(subset = ['ESP.ESPpump.EffiencyESP_d'])\n",
    "    first_result_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + calculated_data_file_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных адаптации после расчета - в папке `adaptation_time_mark`  файл `well_name_adapt_1.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data = prep.load_calculated_data_from_csv(path_to_work_dir + dir_name_with_calculated_data +\n",
    "                                                calculated_data_file_name +  '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение входных данных для адаптации из папки `adaptation_input` и объединение данных адатации и входных данных для нее.\n",
    "Сохранение всех данных в папке `adaptation_time_mark` с названием `well_name_calc_and_input.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(path_to_work_dir + dir_name_with_input_data + input_data_file_name +  '.csv')\n",
    "input_data.index = input_data['Время']\n",
    "del input_data['Время']\n",
    "all_data = input_data.join(calculated_data, how = 'outer')\n",
    "\n",
    "all_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков для данных адаптации в папке  `adaptation_time_mark`\n",
    "\n",
    "Все данные (входные и результаты) на одном графике `well_name_calc_and_input.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_data_traces = pw.create_traces_list_for_all_columms(all_data, 'lines+markers', use_gl = True)\n",
    "plot_file_path = path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.html'\n",
    "pw.plot_subplots(adapt_data_traces, plot_file_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание отчета - набор нужных графиков для быстрой оценки результатов адаптации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qliq = {'Объемный дебит жидкости':['Объемный дебит жидкости (СУ)', 'Q ж, м3/сут (Модель)']}\n",
    "calibrs = {'Калибровки по напору и мощности':\n",
    "       ['К. калибровки по напору - множитель (Модель)',\n",
    "           'К. калибровки по мощности - множитель (Модель)']}\n",
    "metrics = {'Метрики расчета':\n",
    "       ['Значение функции ошибки (Модель)']}\n",
    "gor = {'ГФ (Модель)':['ГФ (Модель)']}\n",
    "wc = {'Обводненность, %':['Обв, % (Модель)']}\n",
    "pressure_intake = {'Давление на приеме': ['Давление на приеме насоса (пласт. жидкость) (СУ)', 'P прием ЭЦН, атм (Модель)']}\n",
    "pressure_wh = {'Рлин': ['Рлин ТМ (Ш)', 'P лин., атм (Модель)']}\n",
    "pressure_bf = {'Рбуф': ['Рбуф (Ш)', 'P буф., атм (Модель)']}\n",
    "temp_intake = {'Температура на приеме насоса': ['Температура на приеме насоса (пласт. жидкость) (СУ)',\n",
    "                                                                      'T прием ЭЦН, C (Модель)']}\n",
    "frequencies = {'Частота, Гц':\n",
    "               ['F вращ ТМ (Ш)', 'Выходная частота ПЧ (СУ)', 'F тока, ГЦ (Модель)']}\n",
    "choke = {'Размер штуцера, мм': ['Dшт (Ш)']}\n",
    "power = {'Активная мощность (СУ)':['Активная мощность (СУ)']}\n",
    "true_power = {'Мощность, передаваемая СУ (Модель)':['Мощность, передаваемая СУ (Модель)']}\n",
    "voltage = {'Напряжение на выходе ТМПН (СУ)':['Напряжение на выходе ТМПН (СУ)']}\n",
    "cos = {'Коэффициент мощности (СУ)':['Коэффициент мощности (СУ)']}\n",
    "\n",
    "efficiency = {'КПД ЭЦН, д.ед.':\n",
    "          ['КПД ЭЦН, д.ед. (Модель)']}\n",
    "dif_pressure = {'Перепад давления в ЭЦН, атм':\n",
    "            ['Перепад давления в ЭЦН, атм (Модель)']}\n",
    "all_banches = [qliq,calibrs,metrics, gor,wc, pressure_intake, pressure_wh, pressure_bf,\n",
    "               temp_intake, frequencies, choke,power,true_power, voltage,cos, efficiency, dif_pressure]\n",
    "\n",
    "pw.create_report_html(all_data, all_banches, path_to_work_dir + dir_name_with_calculated_data + \n",
    "                      well_name + '_adapt_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Генерации данных для восстановления дебитов\n",
    "Работа с калибровками для восстановления дебитов. Для преобразования их выделим в отдельный DataFrame. Будем интерполировать, выкалавать точки, либо еще что-нибудь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_data = calculated_data[['К. калибровки по напору - множитель (Модель)',\n",
    "                               'К. калибровки по мощности - множитель (Модель)']]\n",
    "calibr_data = prep.mark_df_columns(calibr_data, 'Подготовленные')\n",
    "#calibr_data = calibr_data.resample('3h').mean()\n",
    "#calibr_data = calibr_data.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = prep.make_gaps_and_interpolate(calibr_data)\n",
    "calibr_data = result.copy()\n",
    "all_data = all_data.join(calibr_data, how = 'inner')\n",
    "created_input_data = all_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем данные со СУ и шахматки и обработаем их, для генерации входных данных модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_resamle = '3h'\n",
    "created_input_data_type = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_data_cs = prep.load_and_edit_cs_data(cs_data_filename,\n",
    "                                       time_to_resamle, \n",
    "                                       created_input_data_type)\n",
    "chess_data = prep.load_and_edit_chess_data(path_to_work_dir + chess_file_name,\n",
    "                                     time_to_resamle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация входных данных для модели для восстановления дебитов в папку `restore_input_time_mark`\n",
    "* `well_name_restore_input.csv` - входные данных с калибровками (увеличили частоту дискретизации или выкололи точки)\n",
    "* `well_name_restore_input.html` - все входные данные на одном графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir_name = 'restore_input_' + time_mark\n",
    "path_to_input_data = path_to_work_dir + input_data_dir_name + '\\\\'\n",
    "if create_input_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + input_data_dir_name)\n",
    "    except:\n",
    "        pass\n",
    "created_input_data = edited_data_cs.join(chess_data, how = 'outer')\n",
    "created_input_data = created_input_data.join(calibr_data, how ='inner')\n",
    "created_input_data = prep.cut_df(created_input_data, left_boundary, right_boundary)\n",
    "plot_file_path = path_to_input_data + well_name + '_restore_input.html'\n",
    "input_data_traces = pw.create_traces_list_for_all_columms(created_input_data, 'lines+markers', use_gl = True)\n",
    "pw.plot_subplots(input_data_traces, plot_file_path, True)\n",
    "created_input_data.to_csv(path_to_input_data + well_name + '_restore_input.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков в отчетной форме "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qliq = {'Объемный дебит жидкости':['Объемный дебит жидкости (СУ)']}\n",
    "calibrs = {'Калибровки по напору и мощности':\n",
    "       ['К. калибровки по напору - множитель (Модель) (Подготовленные)',\n",
    "           'К. калибровки по мощности - множитель (Модель) (Подготовленные)']}\n",
    "gor = {'ГФ (СУ)':['ГФ (СУ)']}\n",
    "wc = {'Процент обводненности (СУ)':['Процент обводненности (СУ)']}\n",
    "pressure_intake = {'Давление на приеме': ['Давление на приеме насоса (пласт. жидкость) (СУ)']}\n",
    "pressure_wh = {'Рлин': ['Рлин ТМ (Ш)']}\n",
    "pressure_bf = {'Рбуф': ['Рбуф (Ш)']}\n",
    "temp_intake = {'Температура на приеме насоса': ['Температура на приеме насоса (пласт. жидкость) (СУ)']}\n",
    "frequencies = {'Частота, Гц':\n",
    "               ['F вращ ТМ (Ш)', 'Выходная частота ПЧ (СУ)']}\n",
    "choke = {'Размер штуцера, мм': ['Dшт (Ш)']}\n",
    "power = {'Активная мощность (СУ)':['Активная мощность (СУ)']}\n",
    "voltage = {'Напряжение на выходе ТМПН (СУ)':['Напряжение на выходе ТМПН (СУ)']}\n",
    "cos = {'Коэффициент мощности (СУ)':['Коэффициент мощности (СУ)']}\n",
    "\n",
    "all_banches = [qliq,calibrs, gor,wc, pressure_intake, pressure_wh, pressure_bf,\n",
    "               temp_intake, frequencies, choke,power, voltage,cos]\n",
    "\n",
    "pw.create_report_html(created_input_data, all_banches, path_to_input_data  + \n",
    "                      well_name + '_restore_input_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Восстановление дебитов.\n",
    "Нужно, используя сгенерированные данные `well_name_restore_input` восстановить дебиты с помощью `postprocessor.py`\n",
    "Для этого активировать флаги\n",
    "* vfm_calc_option\n",
    "* restore_q_liq_only\n",
    "\n",
    "и определить папку с входными данными `dir_name_with_input_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Работа с данными после восстановления дебитов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Первичная обработка результатов восстановления\n",
    "Обозначим директории с результатами восстановления дебитов и входными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_with_input_data = 'restore_input_2019_11_16_17_36_10' + '\\\\'\n",
    "input_data_file_name = well_name +'_restore_input'\n",
    "dir_name_with_calculated_data = 'restore_2019_11_16_21_31_29' + '\\\\'\n",
    "calculated_data_file_name = well_name +'_restore_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение данных при запуске расчета в многопотоке. Если расчет проводился без многопоточности, этот шаг можно пропустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multiprocessing_on == True:\n",
    "    filenames_list = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path_to_work_dir + dir_name_with_calculated_data + 'multiprocessing\\\\'):\n",
    "        filenames_list.extend(filenames)\n",
    "        break\n",
    "    print(filenames_list)\n",
    "    for i,j in enumerate(filenames_list):\n",
    "        if i == 0:\n",
    "            first_result_data = pd.read_csv(path_to_work_dir + dir_name_with_calculated_data + 'multiprocessing\\\\' + j , parse_dates = True, index_col = 'Время')\n",
    "        else:\n",
    "            another_result_data = pd.read_csv(path_to_work_dir + dir_name_with_calculated_data + 'multiprocessing\\\\' + j , parse_dates = True, index_col = 'Время')\n",
    "            first_result_data = first_result_data.append(another_result_data, sort = True)\n",
    "            del first_result_data['d']\n",
    "            first_result_data = first_result_data.dropna(subset = ['ESP.ESPpump.EffiencyESP_d'])\n",
    "    first_result_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + calculated_data_file_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных после восстановления дебитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data = prep.load_calculated_data_from_csv(path_to_work_dir + dir_name_with_calculated_data +\n",
    "                                                calculated_data_file_name +  '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение входных и выходных данным модели. Сохранение результатов в `well_name_calc_and_input.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(path_to_work_dir + dir_name_with_input_data + input_data_file_name +  '.csv', parse_dates = True, index_col = 'Время')\n",
    "all_data = input_data.join(calculated_data, how = 'outer')\n",
    "all_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков восстановления дебитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_traces = pw.create_traces_list_for_all_columms(all_data, 'lines+markers', use_gl = True)\n",
    "plot_file_path = path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.html'\n",
    "pw.plot_subplots(input_data_traces, plot_file_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Сведение данных адаптации и восстановления\n",
    "Использование файлов типа `calc_and_input` в папках с адаптацией и восстновлением для формирования общего отчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_adapt_dir = 'adaptation_2019_11_15_14_48_55' + '\\\\'\n",
    "path_to_restore_dir = 'restore_2019_11_15_15_13_07' + '\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка и слияние данных адаптации и восстановления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_data_with_input = pd.read_csv(path_to_work_dir + path_to_adapt_dir + well_name + '_calc_and_input' + '.csv' , parse_dates = True, index_col = 'Время')\n",
    "adapt_data_with_input = prep.mark_df_columns(adapt_data_with_input, 'ADAPT')\n",
    "restore_data_with_input = pd.read_csv(path_to_work_dir + path_to_restore_dir + well_name + '_calc_and_input' + '.csv' , parse_dates = True, index_col = 'Время')\n",
    "restore_data_with_input = prep.mark_df_columns(restore_data_with_input, 'RESTORE')\n",
    "overall_data = adapt_data_with_input.join(restore_data_with_input, how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение дебитов методом линейной интерполяции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_liq = overall_data[['Объемный дебит жидкости (СУ) (ADAPT)', 'Активная мощность (СУ) (ADAPT)']]\n",
    "result = prep.make_gaps_and_interpolate(q_liq)\n",
    "result = prep.mark_df_columns(result, 'INTERP')\n",
    "overall_data = overall_data.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заключительная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data['Активная мощность (СУ) (ADAPT)'] = overall_data['Активная мощность (СУ) (ADAPT)'] * 1000\n",
    "overall_data['Активная мощность (СУ) (ADAPT) (INTERP)'] = overall_data['Активная мощность (СУ) (ADAPT) (INTERP)'] * 1000\n",
    "overall_data['Загрузка двигателя (СУ) (ADAPT)'] = overall_data['Загрузка двигателя (СУ) (ADAPT)'] / 100\n",
    "overall_data['Относительная ошибка расчетов (Q ж), %'] = postp.relative_error_perc(overall_data['Объемный дебит жидкости (СУ) (ADAPT)'],\n",
    "                                                                      overall_data['Q ж, м3/сут (Модель) (RESTORE)']).abs()\n",
    "overall_data['Относительная ошибка расчетов (N акт), %'] = postp.relative_error_perc(overall_data['Активная мощность (СУ) (ADAPT)'],\n",
    "                                                                      overall_data['Мощность, передаваемая СУ (Модель) (RESTORE)']).abs()\n",
    "overall_data['Относительная ошибка расчетов (Q ж) (INTERP), %'] = postp.relative_error_perc(overall_data['Объемный дебит жидкости (СУ) (ADAPT)'],\n",
    "                                                                      overall_data['Объемный дебит жидкости (СУ) (ADAPT) (INTERP)']).abs()\n",
    "overall_data['Относительная ошибка расчетов (N акт) (INTERP), %'] = postp.relative_error_perc(overall_data['Активная мощность (СУ) (ADAPT) (INTERP)'],\n",
    "                                                                      overall_data['Мощность, передаваемая СУ (Модель) (RESTORE)']).abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка вывода в отчет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liquid_rates = {'Дебиты': \n",
    "                ['Qж ТМ (Ш) (ADAPT)','Объемный дебит жидкости (СУ) (ADAPT)', 'Q ж, м3/сут (Модель) (ADAPT)',\n",
    "                  'Объемный дебит жидкости (СУ) (ADAPT) (INTERP)', 'Q ж, м3/сут (Модель) (RESTORE)'] }\n",
    "essential_mertics = {'Сравнение методов расчета':\n",
    "                     ['Относительная ошибка расчетов (Q ж), %',\n",
    "            'Относительная ошибка расчетов (Q ж) (INTERP), %']}\n",
    "\n",
    "calibrs = {'Калибровки по напору и мощности':\n",
    "           ['К. калибровки по напору - множитель (Модель) (ADAPT)',\n",
    "               'К. калибровки по мощности - множитель (Модель) (ADAPT)', \n",
    "                  'К. калибровки по напору - множитель (Модель) (RESTORE)',\n",
    "               'К. калибровки по мощности - множитель (Модель) (RESTORE)']}\n",
    "\n",
    "gor_wc = {'ГФ, м3/м3 и Обводненность, %':\n",
    "          ['ГФ (Модель) (ADAPT)', 'Обв, % (Модель) (ADAPT)',\n",
    "                  'ГФ (Модель) (RESTORE)', 'Обв, % (Модель) (RESTORE)']}\n",
    "\n",
    "temperatures = {'Температура, С':\n",
    "                ['T устья, С (Модель) (ADAPT)', 'T устья, С (Модель) (RESTORE)', \n",
    "                'T прием ЭЦН, C (Модель) (ADAPT)', 'T прием ЭЦН, C (Модель) (RESTORE)']}\n",
    "\n",
    "pressures_up = {'Давления (Устьевое и буферное), атм':\n",
    "                ['Рбуф (Ш) (ADAPT)', 'P буф., атм (Модель) (ADAPT)', 'P буф., атм (Модель) (RESTORE)',\n",
    "             'Рлин ТМ (Ш) (ADAPT)', 'P лин., атм (Модель) (ADAPT)', 'P лин., атм (Модель) (RESTORE)']}\n",
    "\n",
    "pressures_down = {'Давления (На приеме), атм':\n",
    "                  ['P прием ЭЦН, атм (Модель) (ADAPT)', 'P прием ЭЦН, атм (Модель) (RESTORE)']}\n",
    "                 \n",
    "frequencies = {'Частота, Гц':\n",
    "               ['F вращ ТМ (Ш) (ADAPT)', 'Выходная частота ПЧ (СУ) (ADAPT)',\n",
    "               'F тока, ГЦ (Модель) (ADAPT)', 'F тока, ГЦ (Модель) (RESTORE)']}\n",
    "\n",
    "beam_sizes = {'Размер штуцера, мм':\n",
    "              ['Dшт (Ш) (ADAPT)', 'Dшт (Ш) (RESTORE)']}\n",
    "\n",
    "powers = {'Активная мощность, Вт':\n",
    "          ['Активная мощность (СУ) (ADAPT)', 'Мощность, передаваемая СУ (Модель) (ADAPT)',\n",
    "           'Активная мощность (СУ) (ADAPT) (INTERP)', 'Мощность, передаваемая СУ (Модель) (RESTORE)']}\n",
    "                       \n",
    "currents= {'Токи, А':\n",
    "           ['Ток фазы А (СУ) (ADAPT)', 'I, А (Модель) (ADAPT)', 'I, А (Модель) (RESTORE)']}\n",
    "               \n",
    "loads = {'Загрузка, д.ед.':\n",
    "         ['Загрузка двигателя (Модель) (ADAPT)', 'Загрузка двигателя (Модель) (RESTORE)']}\n",
    "\n",
    "efficiency = {'КПД ЭЦН, д.ед.':\n",
    "              ['КПД ЭЦН, д.ед. (Модель) (ADAPT)', 'КПД ЭЦН, д.ед. (Модель) (RESTORE)']}\n",
    "\n",
    "metrics = {'Метрики расчета':\n",
    "           ['Значение функции ошибки (Модель) (ADAPT)',\n",
    "                  'Значение функции ошибки (Модель) (RESTORE)',\n",
    "          'Относительная ошибка расчетов (N акт), %',\n",
    "           'Относительная ошибка расчетов (N акт) (INTERP), %']}\n",
    "\n",
    "dif_pressure = {'Перепад давления в ЭЦН, атм':\n",
    "                ['Перепад давления в ЭЦН, атм (Модель) (ADAPT)', 'Перепад давления в ЭЦН, атм (Модель) (RESTORE)']}\n",
    "\n",
    "all_banches = [liquid_rates,essential_mertics, calibrs, metrics, gor_wc, temperatures,pressures_up, \n",
    "               pressures_down,frequencies, beam_sizes,powers, currents,loads,efficiency, dif_pressure]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание сводного отчета `well_name_adapt_and_restore_report.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_path = path_to_work_dir + path_to_restore_dir + well_name + '_adapt_and_restore_report' +  '.html'\n",
    "pw.create_report_html(overall_data, all_banches, plot_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет различных метрик для модели и сохранение их в текстовый файл `well_name_adapt_and_restore_metrics_report.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data_with_calibr_gaps = overall_data[overall_data['К. калибровки по напору - множитель (Модель) (ADAPT)'] !=\n",
    "                                            overall_data['К. калибровки по напору - множитель (Модель) (RESTORE)']]\n",
    "overall_data_with_calibr_gaps = overall_data_with_calibr_gaps.dropna(subset = ['Q ж, м3/сут (Модель) (RESTORE)'])\n",
    "calibr_calc_metrics = postp.calc_mertics(overall_data_with_calibr_gaps['Q ж, м3/сут (Модель) (ADAPT)'],\n",
    "            overall_data_with_calibr_gaps['Q ж, м3/сут (Модель) (RESTORE)'], 'Метрики восстановления Qж с помощью калибровок')\n",
    "calibr_calc_metrics += 'Средняя относительная ошибка Q ж, %: ' + str(overall_data_with_calibr_gaps['Относительная ошибка расчетов (Q ж), %'].abs().mean()) + '\\n'\n",
    "calibr_calc_metrics += 'Средняя относительная ошибка N акт, %: ' + str(overall_data_with_calibr_gaps['Относительная ошибка расчетов (N акт), %'].abs().mean()) + '\\n'\n",
    "\n",
    "interp_calc_metrics = postp.calc_mertics(overall_data_with_calibr_gaps['Объемный дебит жидкости (СУ) (ADAPT)'],\n",
    "            overall_data_with_calibr_gaps['Объемный дебит жидкости (СУ) (ADAPT) (INTERP)'], 'Метрики восстановления Qж с помощью интерполяции')\n",
    "interp_calc_metrics +='Средняя относительная ошибка Q ж (INTERP), %: ' + str(overall_data_with_calibr_gaps['Относительная ошибка расчетов (Q ж) (INTERP), %'].abs().mean()) + '\\n' \n",
    "interp_calc_metrics +='Средняя относительная ошибка N акт (INTERP), %: ' + str(overall_data_with_calibr_gaps['Относительная ошибка расчетов (N акт) (INTERP), %'].abs().mean()) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_text_file_path = path_to_work_dir + path_to_restore_dir + well_name + '_adapt_and_restore_metrics_report' +  '.txt'\n",
    "text_file = open(metrics_text_file_path, \"w\")\n",
    "text_file.write(calibr_calc_metrics + '\\n' + interp_calc_metrics)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конец\n",
    "Основной цикл тетрадки закачивается. Дальше построение полезных графиков, их нужно распихать по модулям и в общий workflow. Тут шаблоны для построения корреляционной и тепловых карт в разном виде, построение напорной характеристики ЭНЦ, обезразмеревание величин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение напорной характеристики ЭЦН"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import download_plotlyjs, plot, iplot\n",
    "    \n",
    "def make_dimensionless_df(df):\n",
    "    result_df_dimensionless = df.copy()\n",
    "    for i in result_df_dimensionless.columns:\n",
    "        if i == 'Время':\n",
    "            del result_df_dimensionless['Время']\n",
    "        else:\n",
    "            new_new = result_df_dimensionless[i]/result_df_dimensionless[i].max()\n",
    "            result_df_dimensionless[i] = new_new\n",
    "\n",
    "    return result_df_dimensionless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_name = \"Техрежим, , февраль 2019.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_file_full_path = os.getcwd() + '\\\\data\\\\tr\\\\' + tr_name\n",
    "tr_data = prep.read_tr_and_get_data(tr_file_full_path, well_name)\n",
    "tr_data_df = pd.DataFrame({'Параметры скважины с ТР': list(tr_data.__dict__.values())})\n",
    "tr_data_df.index = list(tr_data.__dict__.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение метрик и данных по скважине в единый DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_calc_metrics = postp.calc_mertics(overall_data_with_calibr_gaps['Q ж, м3/сут (Модель) (ADAPT)'],\n",
    "            overall_data_with_calibr_gaps['Q ж, м3/сут (Модель) (RESTORE)'], 'Метрики восстановления Qж с помощью калибровок', return_df = True )\n",
    "interp_calc_metrics = postp.calc_mertics(overall_data_with_calibr_gaps['Объемный дебит жидкости (СУ) (ADAPT)'],\n",
    "            overall_data_with_calibr_gaps['Объемный дебит жидкости (СУ) (ADAPT) (INTERP)'], 'Метрики восстановления Qж с помощью интерполяции', return_df = True)\n",
    "overall_metrics = calibr_calc_metrics.append(interp_calc_metrics)\n",
    "overall_metrics['Средняя относительная ошибка Q ж'] = [overall_data_with_calibr_gaps['Относительная ошибка расчетов (Q ж), %'].abs().mean(),\n",
    "                                                      overall_data_with_calibr_gaps['Относительная ошибка расчетов (Q ж) (INTERP), %'].abs().mean()]\n",
    "overall_metrics['Средняя относительная ошибка N акт'] = [overall_data_with_calibr_gaps['Относительная ошибка расчетов (N акт), %'].abs().mean(),\n",
    "                                                      overall_data_with_calibr_gaps['Относительная ошибка расчетов (N акт) (INTERP), %'].abs().mean()]\n",
    "overall_metrics['ЭЦН'] = [tr_data.esp_name_str, tr_data.esp_name_str]\n",
    "overall_metrics['ПЭД'] = [tr_data.motor_name_str, tr_data.motor_name_str]\n",
    "overall_metrics['Кол-во точек (ADAPT)'] = [len(overall_data['К. калибровки по напору - множитель (Модель) (ADAPT)']), len(overall_data['К. калибровки по напору - множитель (Модель) (ADAPT)'])]\n",
    "\n",
    "overall_metrics.index = [well_name + ' (CALIBR)' , well_name + ' (INTERP)']\n",
    "overall_metrics.to_csv(path_to_work_dir + path_to_restore_dir + well_name + '_adapt_restore_metrics_tr_report' +  '.csv')\n",
    "overall_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv(path_to_work_dir + path_to_restore_dir + well_name + '_adapt_restore_metrics_tr_report' +  '.csv', index_col = 'Unnamed: 0')\n",
    "check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_esp_nom_m3day = tr_data.esp_nom_rate_m3day\n",
    "head_esp_nom_m = tr_data.esp_nom_head_m\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "sys.path.append('C:\\\\Users\\\\olegk\\\\Documents\\\\')\n",
    "import unifloc_vba.description_generated.python_api as python_api\n",
    "path_to_addin = os.getcwd()\n",
    "path_to_addin = path_to_addin.replace('unifloc\\\\sandbox\\\\uTools', 'unifloc_vba\\\\UniflocVBA_7.xlam')\n",
    "UniflocVBA = python_api.API(path_to_addin)\n",
    "h_m = []\n",
    "efficency_perc = []\n",
    "power_wt = []\n",
    "q_m3day = list(range(1, int(q_esp_nom_m3day * 1.8),10))\n",
    "pump_id = UniflocVBA.calc_ESP_id_by_rate(q_esp_nom_m3day)\n",
    "num_stages = int(head_esp_nom_m / UniflocVBA.calc_ESP_head_m(q_esp_nom_m3day, pump_id = pump_id))\n",
    "for i in q_m3day:\n",
    "    h_m.append(UniflocVBA.calc_ESP_head_m(i,num_stages = num_stages,  pump_id = pump_id))\n",
    "    power_wt.append(UniflocVBA.calc_ESP_power_W(i, num_stages = num_stages, pump_id = pump_id) / 1000)\n",
    "    efficency_perc.append(UniflocVBA.calc_ESP_eff_fr(i, num_stages = num_stages, pump_id = pump_id) * 100)\n",
    "esp_curve = pd.DataFrame({'Напор, м/100': h_m, 'Мощность, кВт': power_wt, 'КПД, %.': efficency_perc})\n",
    "esp_curve.index = q_m3day\n",
    "\n",
    "esp_curve.head()\n",
    "\n",
    "head_trace = pw.create_plotly_trace(q_m3day, h_m, 'Напор, м')\n",
    "power_trace = pw.create_plotly_trace(q_m3day, power_wt, 'Мощность, кВт')\n",
    "efficiency_trace = pw.create_plotly_trace(q_m3day, efficency_perc, 'КПД, %.')\n",
    "#esp_traces = pw.create_traces_list_for_all_columms(esp_curve, chosen_mode='lines+markers', use_gl=False)\n",
    "#pw.plot_func(esp_traces, 'Характеристика ЭЦН', 'Характеристика ЭЦН.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nedeed_param_list = ['Q ж, м3/сут (Модель) (ADAPT)',\n",
    "                      'ГФ (Модель) (ADAPT)',\n",
    "                     'Обв, % (Модель) (ADAPT)',\n",
    "                     'К. калибровки по напору - множитель (Модель) (ADAPT)',\n",
    "                    'К. калибровки по мощности - множитель (Модель) (ADAPT)', \n",
    "                      'F тока, ГЦ (Модель) (ADAPT)',\n",
    "                     'Мощность, передаваемая СУ (Модель) (ADAPT)',\n",
    "                     'КПД ЭЦН, д.ед. (Модель) (ADAPT)',\n",
    "                     'Перепад давления в ЭЦН, атм (Модель) (ADAPT)',\n",
    "                     'P буф., атм (Модель) (ADAPT)',\n",
    "                     'Рлин ТМ (Ш) (ADAPT)',\n",
    "                     'Давление на приеме насоса (пласт. жидкость) (СУ) (ADAPT)'\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_data_corr = overall_data[nedeed_param_list]\n",
    "all_data_corr = all_data_corr.corr()\n",
    "data=go.Heatmap(\n",
    "       z=all_data_corr.values,\n",
    "       x=list(all_data_corr.columns),\n",
    "       y=list(all_data_corr.index), showscale=False, colorscale = 'RdBu', zmid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data_dimensionless = make_dimensionless_df(overall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_wc_gor = overall_data_dimensionless[['Q ж, м3/сут (Модель) (ADAPT)', 'ГФ (Модель) (ADAPT)', 'Обв, % (Модель) (ADAPT)']]\n",
    "q_wc_gor_trace = pw.create_traces_list_for_all_columms(q_wc_gor)\n",
    "calibrs = overall_data_dimensionless[['К. калибровки по напору - множитель (Модель) (ADAPT)', \n",
    "                                      'К. калибровки по мощности - множитель (Модель) (ADAPT)']]\n",
    "calibrs_trace = pw.create_traces_list_for_all_columms(calibrs)\n",
    "loss =  overall_data_dimensionless[['P буф., атм (Модель) (ADAPT)', \n",
    "                                      'Рлин ТМ (Ш) (ADAPT)',\n",
    "                                   'Мощность, передаваемая СУ (Модель) (ADAPT)']]\n",
    "loss_trace = pw.create_traces_list_for_all_columms(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(\n",
    "    rows=7, cols=1, \n",
    "    specs=[[{\"type\": \"scattergl\"}], [{\"type\": \"scattergl\"}],\n",
    "           [{\"type\": \"scattergl\"}], [{\"type\": \"heatmap\"}],\n",
    "    [{\"type\": \"scattergl\"}], [{\"type\": \"scattergl\"}],\n",
    "    [{\"type\": \"scattergl\"}]]\n",
    ")\n",
    "fig.add_trace(q_wc_gor_trace[0],\n",
    "              row=1, col=1)\n",
    "fig.add_trace(q_wc_gor_trace[1],\n",
    "              row=1, col=1)\n",
    "fig.add_trace(q_wc_gor_trace[2],\n",
    "              row=1, col=1)\n",
    "\n",
    "fig.add_trace(calibrs_trace[0],\n",
    "              row=2, col=1)\n",
    "fig.add_trace(calibrs_trace[1],\n",
    "              row=2, col=1)\n",
    "\n",
    "fig.add_trace(loss_trace[0],\n",
    "              row=3, col=1)\n",
    "fig.add_trace(loss_trace[1],\n",
    "              row=3, col=1)\n",
    "fig.add_trace(loss_trace[2],\n",
    "              row=3, col=1)\n",
    "\n",
    "fig.add_trace(head_trace,\n",
    "              row=4, col=1)\n",
    "fig.add_trace(power_trace,\n",
    "              row=5, col=1)\n",
    "\n",
    "fig.add_trace(efficiency_trace,\n",
    "              row=6, col=1)\n",
    "\n",
    "fig.add_trace(data,\n",
    "              row=7, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=7 * 500,showlegend=True)\n",
    "plot(fig, filename = path_to_work_dir + path_to_restore_dir + well_name + '_dimless_pump_heatmap_report' +  '.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells = [['1628','restore_2019_11_16_17_23_08', 'adaptation_2019_11_16_17_15_24'],\n",
    "         ['601', 'restore_2019_11_16_18_16_52', 'adaptation_2019_11_16_18_13_00'],\n",
    "         ['1602','restore_2019_11_15_20_03_23', 'adaptation_2019_11_15_19_49_55'],\n",
    "         ['1567','restore_2019_11_06_19_17_49', 'adaptation_2019_11_06_19_04_07'],\n",
    "         ['252','restore_2019_11_16_21_31_29', 'adaptation_2019_11_16_17_40_20'],\n",
    "         ['569', 'restore_2019_11_16_15_25_55', 'adaptation_2019_11_16_14_59_46'],\n",
    "         ['1354', 'restore_2019_11_15_15_13_07', 'adaptation_2019_11_15_14_48_55']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_names = ['1628', '601', '1602', '1567', '252', '569', '1354']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in wells:\n",
    "    path = current_path + \"\\\\data\\\\\" + i[0] + '\\\\' + i[1] + '\\\\' + i[0] + '_adapt_restore_metrics_tr_report.csv'\n",
    "    this_data = pd.read_csv(path, index_col = 'Unnamed: 0')\n",
    "    data.append(this_data)\n",
    "start = data[0]\n",
    "for i in data[1:]:\n",
    "    start = start.append(i)\n",
    "#start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = []\n",
    "for i in wells:\n",
    "    path = current_path + \"\\\\data\\\\\" + i[0] + '\\\\' + i[2] + '\\\\' + i[0] + '_calc_and_input.csv'\n",
    "    adapt_data_with_input = pd.read_csv(path, parse_dates = True, index_col = 'Время')\n",
    "    adapt_data_with_input = prep.mark_df_columns(adapt_data_with_input, 'ADAPT')\n",
    "    small_adapt_df = adapt_data_with_input[nedeed_param_list]\n",
    "    small_adapt_df_corr = small_adapt_df.corr()\n",
    "    corr_data.append(small_adapt_df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_corr_data = {}\n",
    "for i in corr_data[0].columns:\n",
    "    this_df = corr_data[0].copy()\n",
    "    for j, k in zip(wells, corr_data) :\n",
    "        well_name = j[0]\n",
    "        this_df[well_name] = k[i]\n",
    "    this_df = this_df[well_names]\n",
    "    this_df = prep.mark_df_columns(this_df, '(скв)')\n",
    "    one_corr_data[i] = this_df\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heat_map_data(df, name):\n",
    "    data=go.Heatmap(\n",
    "           z=df.values,\n",
    "           x=list(df.columns),\n",
    "           y=list(df.index), showscale=False, colorscale = 'RdBu', zmid=0, name = name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = create_heat_map_data(one_corr_data['Мощность, передаваемая СУ (Модель) (ADAPT)'],'Мощность, передаваемая СУ (Модель) (ADAPT)' )\n",
    "iplot([check])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap_report(one_corr_data):\n",
    "    len_all = len(one_corr_data.keys())\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=len_all, cols=1)\n",
    "    for i in range(len_all):\n",
    "        this_name = list(one_corr_data.keys())[i]\n",
    "        data = create_heat_map_data(one_corr_data[this_name], this_name)\n",
    "        this_row = i + 1\n",
    "        fig.add_trace(data,\n",
    "              row=this_row, col=1)\n",
    "    fig.update_layout(height=len_all * 500,showlegend=True)\n",
    "    plot(fig, filename ='heatmap_report' +  '.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap_report(one_corr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, iplot\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_heatmap(df, filename_str):\n",
    "    corrs = df.corr()\n",
    "    figure = ff.create_annotated_heatmap(\n",
    "       z=corrs.values,\n",
    "       x=list(corrs.columns),\n",
    "       y=list(corrs.index),\n",
    "       annotation_text=corrs.round(2).values,\n",
    "       showscale=True)\n",
    "    figure.layout.update(\n",
    "        margin=go.layout.Margin(\n",
    "            l=400,\n",
    "            r=50,\n",
    "            b=100,\n",
    "            t=250\n",
    "        ))\n",
    "    filename_str +='.html'\n",
    "    plot(figure,filename=filename_str)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def plot_scatterplotmatrix(df, file_name):\n",
    "    figure = ff.create_scatterplotmatrix(df, diag='histogram')\n",
    "    figure.layout.update(width=2000, height=1500)\n",
    "    figure.layout.update(font=dict(size=7))\n",
    "    \n",
    "    plot(figure,filename=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_overall_data = overall_data[nedeed_param_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr_heatmap(small_overall_data, 'small_overall_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimenless_small_overall_data = make_dimensionless_df(small_overall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimenless_small_overall_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatterplotmatrix(small_overall_data, 'small_overall_data_scatterplotmatrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
