{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задания для рефакторинга\n",
    "\n",
    "1. Сделать все гибко\n",
    "\n",
    "2. Сделать все красиво\n",
    "\n",
    "3. Сделать все просто\n",
    "\n",
    "4. Сделать все логично\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кобзарь Олег, Хабибуллин Ринат, Буденный Семен, Адрианова Алла, Логинов Александр, Лемихов Александр\n",
    "# Обработчик данных \n",
    "\n",
    "В данной тетрадке собраны все средства для работы с данными (пре- и пост- процессор; генерация входных данных для модели, анализ рассчитанных значений, построение графиков)\n",
    "\n",
    "Большое количество кода вынесено в модуле - здесь в основном управление\n",
    "\n",
    "`well_name` - номер исследуемой скважины, например `1`\n",
    "\n",
    "Исходными данные лежат в папке  `data` в папках, соответствующим названиям скважин. Это данные\n",
    "1. Со станции управления (`data/well_name/well_name.csv`). Большое количество записей, которые нужно преобразовать в \"шахмоткоподобный\" вид для дальнейшей работы. Данные со СУ могут быть как высокочастотными (токи, напряжения), так и низкочастотными. \n",
    "2. С шахматки `data/well_name/Скв. well_name (01.07.2018-31.03.2019).xls`. Низкочастотные данные. \n",
    "3. C техрежима `data/tr/Техрежим, , февраль 2019.xls`. Какой насос спущен, ПЭД, на какую глубину. Эти данные постоянны на всем периоде расчета. В одном файлике один месяц и данные для всех скважин.\n",
    "\n",
    "\n",
    "\n",
    "## Общий workflow\n",
    "Здесь кратко, подробное описание будет над ячейками.\n",
    "1. Обработка исходных данных со СУ и приведение их в удобный формат. (init_edit)\n",
    "2. Считавание подготовленных ранее данных со СУ, шахматки, а затем генерации входных данных для модели, конкретно, адаптации модели скважины за выбранный период времени. (adaptation_input)\n",
    "3. Адаптация. Теперь можно открыть файл processor.py и в нем, выставив настройки и определив входные данные, запустить расчет скважину. После адаптации данные появится данные с калибровочными коэффициентами. (adaptation)\n",
    "4. Считывание рассчитанных значений адаптации, данных со СУ и шахматки. Генерации файлов для восстановления дебитов (restore_input)\n",
    "5. Восстановление. Работа в processor.py, где необходимо изменить метод расчета и указать на новые входные данные. (restore) \n",
    "6. Заключительный анализ: сведение результатов адаптации и восстановления; расчет различных метрик для оценки метода (тоже в папке restore)\n",
    "\n",
    "По идее, если данные уже сгенерированы, каждый пункт может повторяться многократно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт модулей. Некоторые функции и методы вынесены в отдельные `.py`\n",
    "* `preprocessor` - для обработки данных в и из модели\n",
    "* `processor` - для непосредственного запуска расчета адаптации или восстановления\n",
    "* `postprocessor` - для завершающего анализа сгенерированных данных. Определение метрик успешности модели, паттернов, событий, зависимостей.\n",
    "* `plotly_workflow` - для быстрого построения шаблонизированных графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_workflow.plotly_option as pltl_opt\n",
    "import plot_workflow.plotly_workflow as pltl_wf\n",
    "\n",
    "from preproc_p import workflow_cs_data\n",
    "from preproc_p import workflow_chess_data\n",
    "from preproc_p import preproc_tool\n",
    "from preproc_p import workflow_calc_data\n",
    "from preproc_p import workflow_tr_data\n",
    "from preproc_p import filtration\n",
    "from proc_p import processor as proc\n",
    "\n",
    "from ml import calibr_restore as calibr_restore\n",
    "from postproc_p import result_and_metrics as result_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общие настройки и флаги для работы. Указание номера скважины и название файла шахматки. Флаги для запуска тех или иных ячеек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_name = '3922'\n",
    "chess_file_name = f'Скв. {well_name} (01.01.2020-29.02.2020).xls'\n",
    "# TODO убрать флаги\n",
    "read_initial_data = True\n",
    "plot_initial_data = True\n",
    "create_input_data = True\n",
    "auto_open_html = True\n",
    "multiprocessing_on = True #TODO может быть убрать флаги, как лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data_full_path = preproc_tool.find_full_path_by_pattern(os.getcwd(), \"*static_data.xlsx*\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение путей к данным. Создание метки времени к генерируемым папкам. (чтоб данные не перезаписывались)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "time_mark = '' #datetime.datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "path_to_data = current_path + \"\\\\data\\\\\"\n",
    "path_to_work_dir = current_path + \"\\\\data\\\\\" + well_name +  \"\\\\\"\n",
    "save_dir_name = 'init_edit'\n",
    "path_to_save = path_to_work_dir + save_dir_name + '\\\\'\n",
    "dirnames_list = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(path_to_data):\n",
    "    dirnames_list.extend(dirnames)\n",
    "    break\n",
    "print(dirnames_list)\n",
    "dynamic_data_full_path = path_to_save + well_name + \"_first_edit.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание интервалов, на которых будет вестить расчет. Их может быть несколько. Рекомендуется поставить малый период времени, выявить ошибки, а затем запускать на месяцы и годы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left_boundary = [datetime.datetime(2018,8,1), datetime.datetime(2018,11,29)]\n",
    "#right_boundary = [datetime.datetime(2018,11,5), datetime.datetime(2019,2,28)]\n",
    "#left_boundary = [datetime.datetime(2018,8,3), datetime.datetime(2018,11,29),   datetime.datetime(2019,2,19)]\n",
    "#right_boundary = [datetime.datetime(2018,11,6), datetime.datetime(2019,2,4),  datetime.datetime(2019,2,28)]\n",
    "#left_boundary = [datetime.datetime(2019,1,30)]\n",
    "#right_boundary = [datetime.datetime(2019,2,28)]\n",
    "left_boundary = [datetime.datetime(2018,6,27)]\n",
    "right_boundary = [datetime.datetime(2020,7,27)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение функции которая все запустит в многопотоке и произведет из данного ноутбука адаптацию и восстановление. (Временный костыль - работает только здесь, в модуле не может)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_calculation(thread_option_list):\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(amount_of_threads) as p:\n",
    "            p.map(proc.calc,\n",
    "                  thread_option_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_names = preproc_tool.GlobalNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учет ВСП"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_stops_path = preproc_tool.find_full_path_by_pattern(os.getcwd(), \"*Вынгаяхинское ВСП*\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_stops = pd.read_csv(well_stops_path, delimiter = ';', engine = 'python')\n",
    "well_stops = well_stops[well_stops['Скв'] == int(well_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_stops_start = well_stops['ДатаСтарта'].values\n",
    "well_stops_end = well_stops['Дата_Окончания'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(well_stops_start)):\n",
    "    well_stops_start[i] = pd.to_datetime(well_stops_start[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(well_stops_end)):\n",
    "    well_stops_end[i] = pd.to_datetime(well_stops_end[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_stops_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_stops_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_boundary = list(well_stops_start)\n",
    "right_boundary = list(well_stops_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Обработка исходных данных\n",
    "Чтение исходных данных `well_name.csv` со СУ и преобразование их в удобный формат. Процесс небыстрый из-за несовершенства алгоритма форматирования и количества данных (около 1-1,5 млн. записей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "if read_initial_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + save_dir_name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с данными ГРАД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data_full_path = preproc_tool.find_full_path_by_pattern(os.getcwd(), f\"*{well_name}.csv*\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data = workflow_cs_data.read_and_format_good_tm_data(well_name, grad_data_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data.to_csv(path_to_save + well_name + \"_first_edit_grad.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_grad = pltl_wf.create_traces_list_for_all_columms(grad_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "pltl_wf.plot_subplots(well_traces_grad,  path_to_save + well_name + \"_first_edit_grad.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с данными со СУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data_full_path = preproc_tool.find_full_path_by_pattern(os.getcwd(), f\"*{well_name}*\", 'флэш')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cs_data = workflow_cs_data.read_and_format_bad_tm_data(cs_data_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data.to_csv(path_to_save + well_name + \"_first_edit_cs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_cs = pltl_wf.create_traces_list_for_all_columms(cs_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "pltl_wf.plot_subplots(well_traces_cs,  path_to_save + well_name + \"_first_edit_cs.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с данными шахматки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data = workflow_chess_data.load_and_edit_chess_data(path_to_work_dir + chess_file_name,\n",
    "                                         '1d', without_changing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data.to_csv(path_to_save + well_name + \"_first_edit_chess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_chess = pltl_wf.create_traces_list_for_all_columms(chess_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "\n",
    "pltl_wf.plot_subplots(well_traces_chess,  path_to_save + well_name + \"_first_edit_chess.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков для нескольких интересующих параметров по исходным данных со СУ в `well_name__first_edit_report.html`. Процесс занимает около 3-5 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение данных в единый динамический DataFrame\n",
    "\n",
    "переименование нужных параметров, добавление меток источников данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data_edited = pd.read_csv(\n",
    "    path_to_save + well_name + \"_first_edit_grad.csv\", index_col='Время', parse_dates=True, dayfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data_edited = preproc_tool.rename_columns_by_dict(grad_data_edited)\n",
    "grad_data_edited = preproc_tool.solve_dimensions(grad_data_edited)\n",
    "grad_data_edited = preproc_tool.mark_df_columns(grad_data_edited, \"ГРАД\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data_edited = pd.read_csv(\n",
    "    path_to_save + well_name + \"_first_edit_cs.csv\", index_col='Время', parse_dates=True, dayfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data_edited = preproc_tool.rename_columns_by_dict(cs_data_edited)\n",
    "cs_data_edited = preproc_tool.solve_dimensions(cs_data_edited)\n",
    "cs_data_edited = preproc_tool.mark_df_columns(cs_data_edited, \"СУ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data_edited = pd.read_csv(\n",
    "    path_to_save + well_name + \"_first_edit_chess.csv\", index_col='Время', parse_dates=True, dayfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data_edited = preproc_tool.rename_columns_by_dict(chess_data_edited)\n",
    "chess_data_edited = preproc_tool.solve_dimensions(chess_data_edited)\n",
    "chess_data_edited = preproc_tool.mark_df_columns(chess_data_edited, \"ШТР\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = grad_data_edited.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = dynamic_data.join(cs_data_edited, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = dynamic_data.join(chess_data_edited, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = dynamic_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_dim(values, critical_value, multyplier):\n",
    "    new_values = []\n",
    "    for i in values:\n",
    "        if i > critical_value:\n",
    "            this_value = i * multyplier\n",
    "            new_values.append(this_value)\n",
    "        else:\n",
    "            new_values.append(i)\n",
    "    return new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data[global_names.p_lin_atm + \" (ГРАД)\"] = solve_dim(dynamic_data[global_names.p_lin_atm + \" (ГРАД)\"].values, 40, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data[global_names.cos_phi_d + \" (ГРАД)\"] = solve_dim(dynamic_data[global_names.cos_phi_d + \" (ГРАД)\"].values, 1.1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data.to_csv(path_to_save + well_name + \"_first_edit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_dynamic_data = pltl_wf.create_traces_list_for_all_columms(dynamic_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "\n",
    "pltl_wf.plot_subplots(well_traces_dynamic_data,  path_to_save + well_name + \"_first_edit.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Возможно надо сделать репорты для СУ и ШТР"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Вторичная обработка исходных данных для использования в модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного этапа уже нужные обработанные данные со станции управления.\n",
    "\n",
    "Чтение исходных данных со СУ (в уже подготовленных). Обработка этих данных - ресемпл, пометка названий столбцов с помощью `(СУ)`. Т.к. данные высокочастотные, осредним их по 3 часам - примерному времени замера дебита скважины на АГЗУ. Обработка будет отличаться в зависимости от того, какие данные вы генерируете - для адаптации выбрасываются интервалы без замеров дебитов, для восстановления - нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = pd.read_csv(dynamic_data_full_path, index_col = 'Время', parse_dates = True)\n",
    "prepared_dynamic_data = dynamic_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_tool.find_column_in_df_columns(dynamic_data, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_names.chosen_q_liq_m3day = global_names.q_liq_m3day + ' (ГРАД)'\n",
    "global_names.chosen_watercut_perc = global_names.watercut_perc + ' (ГРАД)'\n",
    "global_names.chosen_gor_m3m3 = None\n",
    "\n",
    "global_names.chosen_p_buf_atm = global_names.p_lin_atm + ' (ГРАД)'\n",
    "global_names.chosen_p_intake_atm = global_names.p_intake_atm + ' (ГРАД)'\n",
    "global_names.chosen_t_intake_c =  global_names.t_intake_c + ' (ГРАД)'\n",
    "\n",
    "global_names.chosen_d_choke_mm = 'Dшт (ШТР)'\n",
    "\n",
    "global_names.chosen_cos_phi_d = global_names.cos_phi_d + ' (ГРАД)'\n",
    "global_names.chosen_i_a_motor_a = global_names.i_a_motor_a + ' (ГРАД)'\n",
    "global_names.chosen_u_motor_v = None\n",
    "global_names.chosen_motor_load_perc = global_names.motor_load_perc + ' (ГРАД)'\n",
    "global_names.chosen_freq_hz = global_names.freq_hz + ' (ГРАД)'\n",
    "global_names.chosen_active_power_kwt = global_names.active_power_kwt + ' (ГРАД)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_names.chosen_gor_m3m3 = global_names.gor_m3m3\n",
    "global_names.chosen_d_choke_mm =  global_names.d_choke_mm\n",
    "global_names.chosen_u_motor_v =  global_names.u_motor_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dynamic_data[global_names.q_liq_m3day] = prepared_dynamic_data[global_names.chosen_q_liq_m3day]\n",
    "prepared_dynamic_data[global_names.watercut_perc] = prepared_dynamic_data[global_names.chosen_freq_hz] * 0 + 85\n",
    "\n",
    "prepared_dynamic_data[global_names.p_buf_atm] = prepared_dynamic_data[global_names.chosen_p_buf_atm]\n",
    "prepared_dynamic_data[global_names.p_intake_atm] = prepared_dynamic_data[global_names.chosen_p_intake_atm]\n",
    "prepared_dynamic_data[global_names.t_intake_c] = prepared_dynamic_data[global_names.chosen_t_intake_c]\n",
    "\n",
    "prepared_dynamic_data[global_names.d_choke_mm] = prepared_dynamic_data[global_names.chosen_freq_hz] * 0 + 32\n",
    "\n",
    "prepared_dynamic_data[global_names.cos_phi_d] = prepared_dynamic_data[global_names.chosen_cos_phi_d]\n",
    "prepared_dynamic_data[global_names.i_a_motor_a] = prepared_dynamic_data[global_names.chosen_i_a_motor_a]\n",
    "prepared_dynamic_data[global_names.motor_load_perc] = prepared_dynamic_data[global_names.chosen_motor_load_perc]\n",
    "prepared_dynamic_data[global_names.freq_hz] = prepared_dynamic_data[global_names.chosen_freq_hz]\n",
    "prepared_dynamic_data[global_names.active_power_kwt] = prepared_dynamic_data[global_names.chosen_active_power_kwt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dynamic_data[global_names.u_motor_v] = prepared_dynamic_data[global_names.active_power_kwt] * 1000 / \\\n",
    "                                                prepared_dynamic_data[global_names.i_a_motor_a + ' (ГРАД)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dynamic_data[global_names.gor_m3m3] = prepared_dynamic_data[global_names.chosen_freq_hz] * 0 + 186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dynamic_data[global_names.gor_m3m3] = (prepared_dynamic_data[global_names.q_gas_m3day +' (ГРАД)']   /\n",
    "                        (prepared_dynamic_data[global_names.q_liq_m3day] * (1 - prepared_dynamic_data[global_names.watercut_perc] / 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тут должна быть фильтрация, удаление мусора из колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(report_type = 'second_edit_data')\n",
    "pltl_wf.create_report_html(prepared_dynamic_data, all_banches, path_to_save + well_name + \"_second_edit_report.html\",  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dynamic_data.to_csv(path_to_save + well_name + \"_second_edit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_prepared_dynamic_data = pltl_wf.create_traces_list_for_all_columms(prepared_dynamic_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "\n",
    "pltl_wf.plot_subplots(well_traces_prepared_dynamic_data,  path_to_save + well_name + \"_second_edit.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тут общий ресемпл (возможно нет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Подготовка данных к адаптации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_resamle = '1h'\n",
    "input_data_dir_name = 'adapt_input_' + time_mark\n",
    "path_to_input_data = path_to_work_dir + input_data_dir_name + '\\\\'\n",
    "plot_file_path = path_to_input_data + well_name\n",
    "if create_input_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + input_data_dir_name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dynamic_data = pd.read_csv(path_to_save + well_name + \"_second_edit.csv\", index_col = 'Время', parse_dates = True, dayfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data = prepared_dynamic_data.resample(time_to_resamle).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data[global_names.watercut_perc] = adapt_input_dynamic_data[global_names.watercut_perc].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data = adapt_input_dynamic_data.dropna(subset = [global_names.q_liq_m3day])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data = adapt_input_dynamic_data.dropna(subset = [global_names.p_intake_atm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут не должно быть фильтрации, но должен быть чек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data = filtration.get_filtred_by_sigma(adapt_input_dynamic_data, global_names.q_liq_m3day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data = preproc_tool.cut_df(adapt_input_dynamic_data, left_boundary, right_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data = preproc_tool.fill_input_data(adapt_input_dynamic_data, global_names.return_essential_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(report_type = 'second_edit_data')\n",
    "pltl_wf.create_report_html(adapt_input_dynamic_data, all_banches, plot_file_path + \"_adapt_input_report.html\",  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traces_adapt_input_dynamic_data = pltl_wf.create_traces_list_for_all_columms(adapt_input_dynamic_data, \n",
    "                                                         'lines+markers',\n",
    "                                                         use_gl = True)\n",
    "pltl_wf.plot_subplots(well_traces_adapt_input_dynamic_data,  plot_file_path + \"_adapt_input.html\", two_equal_subplots = True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_input_dynamic_data.to_csv(path_to_input_data + well_name + '_adapt_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация входных данных для адаптации. Сведение данных с шахматки и со СУ. Создание папки с названием `adapt_input_` и временной пометкой и помещение в нее:\n",
    "* сгенерированных входных данных для модели `well_name_adapt_input.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все входные данные на графике `well_name_adapt_input.html` в той же папке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение кривых в отчете только для тех данных, которые будут использоваться в модели в `well_name_adapt_input_report.html` в той же папке в стандартном виде. Можно настроить, какие данные выводить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Адаптация\n",
    "Нужно, используя сгенерированные данные `well_name_adapt_input` получить значения коэффициентов калибровок по напору и мощности с помощью `processor.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка к параллельному расчету.\n",
    "\n",
    "В проекте UniflocVBA нужно вручную размножить надстройки до нужного количества потоков - каждая надстройка будет работать параллельно и рассчитывать определенную часть общих данных. \n",
    "\n",
    "По умолчанию выставлено 4 потока на 4 надстройках `UniflocVBA_7.xlam`, `UniflocVBA_7_1.xlam`, `UniflocVBA_7_2.xlam`, `UniflocVBA_7_3.xlam`. При желании можно добавить еще, не забыв изменить также номера потоков и их общее количество.\n",
    "\n",
    "Группировка информации о потоках в единый список `thread_option_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка многопоточности\n",
    "amount_of_threads = 12\n",
    "dir_name_with_input_data = 'adapt_input_'\n",
    "\n",
    "thread_option_list =proc.create_thread_list(well_name, dir_name_with_input_data, static_data_full_path,\n",
    "                       amount_of_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск процесса адаптации - получения калибровок. Процесс может быть долгим - в среднем расчет идет медленнее, чем при восстановлении дебитов. \n",
    "\n",
    "Рассчет 1 месяца в среднем занимает около 15-20 минут.\n",
    "\n",
    "Стоит отметить, что для аварийного выхода нужно вручную закрыть надстройки Excel (окна, которые открыты и в них ведется работа). После закрытия всех четырех процесс остановится и возникнет ошибка, контроль над jupyter notebook вернется и можно будет работать.\n",
    "\n",
    "Поэтому для тщательной отладки `processor.py` рекомендуется запускать отдельно (лучше через PyCharm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_calculation(thread_option_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Загрузка и анализ адаптации\n",
    "После успешной адаптации нужно проанализировать ее корректность, построив графики. Для этого нужно указать директории с \n",
    "* результатами адапатации - `adaptation`  \n",
    "* входными данными для адаптации - `adapt_input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_with_input_data = 'adapt_input_' + '\\\\'\n",
    "input_data_file_name = well_name + '_adapt_input'\n",
    "dir_name_with_calculated_data = 'adaptation_' + '\\\\'\n",
    "calculated_data_file_name = well_name + '_adapt_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если расчет проводился в многопоточном варианте, то загрузка будет отличаться. В папке с расчетами `adaptation` в сабдиректории `multiprocessing` будут результаты по частям в разных файликах, поэтому их нужно собрать в один файлик и поместить на уровень выше в `adaptation`. Если расчет был без использования многопоточности, этот шаг можно пропустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multiprocessing_on == True:\n",
    "    first_result_data = preproc_tool.combine_multiprocessing_result(path_to_work_dir, dir_name_with_calculated_data)\n",
    "    first_result_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + calculated_data_file_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных адаптации после расчета - в папке `adaptation_time_mark`  файл `well_name_adapt_1.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data = workflow_calc_data.load_calculated_data_from_csv(path_to_work_dir + dir_name_with_calculated_data +\n",
    "                                                calculated_data_file_name +  '.csv', \"ADAPT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение входных данных для адаптации из папки `adaptation_input` и объединение данных адатации и входных данных для нее.\n",
    "Сохранение всех данных в папке `adaptation_time_mark` с названием `well_name_calc_and_input.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(path_to_work_dir + dir_name_with_input_data + input_data_file_name +  '.csv',index_col = 'Время', parse_dates = True)\n",
    "all_data = input_data.join(calculated_data, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pd.isna(all_data.iloc[0][0]):\n",
    "    print('Удаление пустой первой строки')\n",
    "    all_data = all_data.drop(index = all_data.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков для данных адаптации в папке  `adaptation`\n",
    "\n",
    "Все данные (входные и результаты) на одном графике `well_name_calc_and_input.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_data_traces = pltl_wf.create_traces_list_for_all_columms(all_data, 'lines+markers', use_gl = True)\n",
    "plot_file_path = path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.html'\n",
    "pltl_wf.plot_subplots(adapt_data_traces, plot_file_path, True, auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание отчета - набор нужных графиков для быстрой оценки результатов адаптации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(report_type = 'adaptation')\n",
    "\n",
    "pltl_wf.create_report_html(all_data, all_banches, path_to_work_dir + dir_name_with_calculated_data + \n",
    "                      well_name + '_adapt_report.html',  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод обезразмеренных величин, тепловой карты для корреляции между параметрами, напорной характеристики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data_path = preproc_tool.find_full_path_by_pattern(os.getcwd(), '*static_data.xlsx*')\n",
    "static_data = workflow_tr_data.Static_data()\n",
    "static_data_df = pd.read_excel(static_data_path[0])\n",
    "static_data = workflow_tr_data.fill_static_data_structure_by_df(static_data, static_data_df, well_name + \" (ready)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unifloc_vba.description_generated.python_api as python_api\n",
    "path_to_addin = os.getcwd()\n",
    "path_to_addin = path_to_addin.replace('unifloc\\\\sandbox\\\\uTools', 'unifloc_vba\\\\UniflocVBA_7.xlam')\n",
    "UniflocVBA = python_api.API(path_to_addin)\n",
    "esp_traces = pltl_wf.create_esp_traces(UniflocVBA, static_data.esp_nom_rate_m3day, static_data.esp_nom_head_m, static_data.esp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp_df = all_data[[global_names.dp_esp_atm + \" (ADAPT)\",\n",
    "          global_names.esp_head_m + \" (ADAPT)\",\n",
    "          global_names.efficiency_esp_d + \" (ADAPT)\",\n",
    "          global_names.q_mix_mean_m3day + \" (ADAPT)\", \n",
    "          global_names.PowerESP_kwt + \" (ADAPT)\", \n",
    "          global_names.gas_fraction_intake_d + \" (ADAPT)\",\n",
    "          global_names.rs_intake_m3m3 + \" (ADAPT)\",\n",
    "          global_names.c_calibr_head_d + \" (ADAPT)\",\n",
    "          global_names.c_calibr_power_d + \" (ADAPT)\"]]\n",
    "esp_df = esp_df.set_index(esp_df[global_names.q_mix_mean_m3day + \" (ADAPT)\"])\n",
    "esp_df_traces = pltl_wf.create_traces_list_for_all_columms(esp_df, chosen_mode = 'markers', use_gl = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_data_dimensionless = result_and_metrics.make_dimensionless_df(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path_to_work_dir + dir_name_with_calculated_data + well_name + '_dimless_pump_heatmap_report' + '.html'\n",
    "pltl_wf.create_overall_report(all_data, adapt_data_dimensionless, esp_traces, filename, esp_df_traces,  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Загрузка данных адаптации для работы над восстановлением дебитов и прогнозом\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_with_input_data = 'adapt_input_' + '\\\\'\n",
    "input_data_file_name = well_name + '_adapt_input'\n",
    "dir_name_with_calculated_data = 'adaptation_' + '\\\\'\n",
    "calculated_data_file_name = well_name + '_adapt_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data = pd.read_csv(path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.csv', \n",
    "                             index_col = 'Время', parse_dates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_data = calculated_data[[global_names.c_calibr_head_d + ' (ADAPT)',\n",
    "                               global_names.c_calibr_power_d + ' (ADAPT)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = calculated_data[[global_names.p_intake_atm, \n",
    "                               global_names.t_intake_c,\n",
    "                               global_names.active_power_kwt, \n",
    "                               global_names.u_motor_v, \n",
    "                               global_names.p_buf_atm,\n",
    "                               global_names.cos_phi_d,\n",
    "                               global_names.freq_hz,\n",
    "                               global_names.d_choke_mm]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_data_without_index = calibr_data.reset_index()\n",
    "feature_data_without_index = feature_data.reset_index()\n",
    "calculated_data_without_index = calculated_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1.1 Генерации данных для прогнозирования дебитов с помощью ML \n",
    "\n",
    "(back allocation, проверка back allocation)\n",
    "\n",
    "Работа с калибровками для восстановления дебитов. Для преобразования их выделим в отдельный DataFrame. Будем интерполировать, выкалавать точки, либо еще что-нибудь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data_x_train, calculated_data_x_test, calculated_data_y_train, calculated_data_y_test = calibr_restore.get_test_train_drop_2_points(calculated_data_without_index, calculated_data_without_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = calibr_restore.get_test_train_drop_2_points(feature_data_without_index, calibr_data_without_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_train_time = calibr_restore.extract_time_from_df(x_train)\n",
    "x_test, x_test_time = calibr_restore.extract_time_from_df(x_test)\n",
    "y_train, y_train_time = calibr_restore.extract_time_from_df(y_train)\n",
    "y_test, y_test_time = calibr_restore.extract_time_from_df(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_calibr_pred = calibr_restore.restore_calibr_via_ridge(x_train, x_test, y_train[global_names.c_calibr_head_d + ' (ADAPT)']) \n",
    "power_calibr_pred = calibr_restore.restore_calibr_via_ridge(x_train, x_test, y_train[global_names.c_calibr_power_d + ' (ADAPT)'])\n",
    "                                                                             \n",
    "                                                                             \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[global_names.c_calibr_head_d] = head_calibr_pred\n",
    "y_test[global_names.c_calibr_power_d] = power_calibr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[global_names.q_liq_m3day] = calculated_data_y_test[global_names.q_liq_m3day]\n",
    "y_test[global_names.gor_m3m3] = calculated_data_y_test[global_names.gor_m3m3]\n",
    "y_test[global_names.watercut_perc] = calculated_data_y_test[global_names.watercut_perc]\n",
    "y_test[global_names.motor_load_perc] = calculated_data_y_test[global_names.motor_load_perc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.set_index(y_test_time)\n",
    "x_test = x_test.set_index(x_test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_data = x_test.join(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация входных данных для модели для восстановления дебитов в папку `restore_input_time_mark`\n",
    "* `well_name_restore_input.csv` - входные данных с калибровками (увеличили частоту дискретизации или выкололи точки)\n",
    "* `well_name_restore_input.html` - все входные данные на одном графике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1.2 Генерации данных для прогнозирования дебитов с помощью ML \n",
    "\n",
    "forecast\n",
    "\n",
    "Работа с калибровками для прогнозирования дебитов. Для преобразования их выделим в отдельный DataFrame. Будем интерполировать, выкалавать точки, либо еще что-нибудь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data_for_forecast = calculated_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_data_for_forecast = calibr_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_for_forecast = feature_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forecast(x_true, y_true, x_forecast, power = 1):\n",
    "    z = np.polyfit(x_true, y_true, 1)\n",
    "    f = np.poly1d(z)\n",
    "    y_forecast = f(x_forecast)\n",
    "    return y_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forecast_with_time(df_input, parameter_to_forecast_str, n_ticks_to_learn, n_ticks_to_forecast, power = 1):\n",
    "    df = df_input.copy()\n",
    "    day_value = 86400000000000\n",
    "    df.index = df.index.astype(int)\n",
    "    \n",
    "    border_to_learn = df.index[-1] - n_ticks_to_learn * day_value\n",
    "    df_to_learn = df[df.index > border_to_learn]\n",
    "    series_to_learn = df_to_learn[parameter_to_forecast_str]\n",
    "    x_true = series_to_learn.index\n",
    "    y_true = series_to_learn.values\n",
    "    x_to_forecast = np.arange(x_true[-1], x_true[-1] + n_ticks_to_forecast * day_value, day_value)\n",
    "    y_forecast = linear_forecast(x_true, y_true, x_to_forecast, power)\n",
    "    x_forecast_as_time = pd.to_datetime(x_to_forecast)\n",
    "    return x_forecast_as_time, y_forecast    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasted_calculated_data = {}\n",
    "n_ticks_to_learn = 3\n",
    "n_ticks_to_forecast = 3\n",
    "for i in global_names.return_essential_parameters():\n",
    "    time_index, this_parameter_forecast = linear_forecast_with_time(calculated_data_for_forecast,\n",
    "                                                        i, n_ticks_to_learn, n_ticks_to_forecast, power = 1)\n",
    "    forecasted_calculated_data[i] = this_parameter_forecast\n",
    "forecasted_calculated_data = pd.DataFrame(forecasted_calculated_data)\n",
    "forecasted_calculated_data.index = time_index\n",
    "forecasted_calculated_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasted_calculated_data[global_names.d_choke_mm] = forecasted_calculated_data[global_names.p_intake_atm] * 0 + 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = calculated_data_for_forecast[[global_names.p_intake_atm, \n",
    "                               global_names.t_intake_c,\n",
    "                               global_names.active_power_kwt, \n",
    "                               global_names.u_motor_v, \n",
    "                               global_names.p_buf_atm,\n",
    "                               global_names.cos_phi_d,\n",
    "                               global_names.freq_hz,\n",
    "                               global_names.d_choke_mm]].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = calculated_data_for_forecast[[global_names.c_calibr_head_d + ' (ADAPT)', \n",
    "                                        global_names.c_calibr_power_d + ' (ADAPT)']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = forecasted_calculated_data[[global_names.p_intake_atm, \n",
    "                               global_names.t_intake_c,\n",
    "                               global_names.active_power_kwt, \n",
    "                               global_names.u_motor_v, \n",
    "                               global_names.p_buf_atm,\n",
    "                               global_names.cos_phi_d,\n",
    "                               global_names.freq_hz,\n",
    "                               global_names.d_choke_mm]].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_calibr_pred = calibr_restore.restore_calibr_via_ridge(x_train, x_test, y_train[global_names.c_calibr_head_d + ' (ADAPT)']) \n",
    "power_calibr_pred = calibr_restore.restore_calibr_via_ridge(x_train, x_test, y_train[global_names.c_calibr_power_d + ' (ADAPT)'])\n",
    "                                                                             \n",
    "                          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_data = forecasted_calculated_data.copy()\n",
    "predict_input_data[global_names.c_calibr_head_d] = head_calibr_pred\n",
    "predict_input_data[global_names.c_calibr_power_d] = power_calibr_pred\n",
    "predict_input_data.index = forecasted_calculated_data.index\n",
    "predict_input_data.index.name = 'Время'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Построение графиков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_data = preproc_tool.fill_input_data(predict_input_data, global_names.return_essential_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir_name = 'restore_input_' + time_mark\n",
    "path_to_input_data = path_to_work_dir + input_data_dir_name + '\\\\'\n",
    "if create_input_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + input_data_dir_name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_data.to_csv(path_to_input_data + well_name + '_restore_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_path = path_to_input_data + well_name + '_restore_input.html'\n",
    "input_data_traces = pltl_wf.create_traces_list_for_all_columms(predict_input_data, 'lines+markers', use_gl = True)\n",
    "pltl_wf.plot_subplots(input_data_traces, plot_file_path, True,  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков в отчетной форме "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(report_type = 'forecast_input')\n",
    "\n",
    "pltl_wf.create_report_html(predict_input_data, all_banches, path_to_input_data  + \n",
    "                      well_name + '_restore_input_report.html',  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Восстановление дебитов.\n",
    "Нужно, используя сгенерированные данные `well_name_restore_input` восстановить дебиты с помощью `postprocessor.py`\n",
    "Для этого активировать флаги\n",
    "* vfm_calc_option = True\n",
    "* restore_q_liq_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка к параллельному расчету.\n",
    "\n",
    "В проекте UniflocVBA нужно вручную размножить надстройки до нужного количества потоков - каждая надстройка будет работать параллельно и рассчитывать определенную часть общих данных. \n",
    "\n",
    "По умолчанию выставлено 4 потока на 4 надстройках `UniflocVBA_7.xlam`, `UniflocVBA_7_1.xlam`, `UniflocVBA_7_2.xlam`, `UniflocVBA_7_3.xlam`. При желании можно добавить еще, не забыв изменить также номера потоков и их общее количество.\n",
    "\n",
    "Группировка информации о потоках в единый список `thread_option_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка многопоточности\n",
    "\n",
    "amount_of_threads = 1\n",
    "dir_name_with_input_data = 'restore_input_'\n",
    "\n",
    "thread_option_list =proc.create_thread_list(well_name, dir_name_with_input_data, static_data_full_path,\n",
    "                       amount_of_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск процесса восстановления дебитов. Процесс может быть долгим - в среднем расчет восстановления дебитов идет быстрее, чем при адаптации (получении калибровок). \n",
    "\n",
    "Рассчет 1 месяца в среднем занимает около 10-15 минут.\n",
    "\n",
    "Стоит отметить, что для аварийного выхода нужно вручную закрыть надстройки Excel (окна, которые открыты и в них ведется работа). После закрытия всех четырех процесс остановится и возникнет ошибка, контроль над jupyter notebook вернется и можно будет работать.\n",
    "\n",
    "Поэтому для тщательной отладки processor.py рекомендуется его запускать отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "run_calculation(thread_option_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты расчета появятся в `well_name/restore_time_mark/multiprocessing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Подведение итогов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Первичная обработка результатов прогноза\n",
    "Обозначим директории с результатами восстановления дебитов и входными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_with_input_data = 'restore_input_' + '\\\\'\n",
    "input_data_file_name = well_name +'_restore_input'\n",
    "dir_name_with_calculated_data = 'restore_' + '\\\\'\n",
    "calculated_data_file_name = well_name +'_restore_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение данных при запуске расчета в многопотоке. Если расчет проводился без многопоточности, этот шаг можно пропустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multiprocessing_on == True:\n",
    "    first_result_data = preproc_tool.combine_multiprocessing_result(path_to_work_dir, dir_name_with_calculated_data)\n",
    "    first_result_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + calculated_data_file_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных после восстановления дебитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data = workflow_calc_data.load_calculated_data_from_csv(path_to_work_dir + dir_name_with_calculated_data +\n",
    "                                                calculated_data_file_name +  '.csv', \"PREDICTION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение входных и выходных данным модели. Сохранение результатов в `well_name_calc_and_input.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(path_to_work_dir + dir_name_with_input_data + input_data_file_name +  '.csv', parse_dates = True, index_col = 'Время')\n",
    "all_data = input_data.join(calculated_data, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pd.isna(all_data.iloc[0][0]):\n",
    "    print('Удаление пустой первой строки')\n",
    "    all_data = all_data.drop(index = all_data.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков восстановления дебитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_traces = pltl_wf.create_traces_list_for_all_columms(all_data, 'lines+markers', use_gl = True)\n",
    "plot_file_path = path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.html'\n",
    "pltl_wf.plot_subplots(input_data_traces, plot_file_path, True,  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(report_type = 'prediction')\n",
    "\n",
    "pltl_wf.create_report_html(all_data, all_banches, path_to_work_dir  + \n",
    "                      dir_name_with_calculated_data + well_name + '_prediction_report.html',  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(report_type = 'forecast')\n",
    "\n",
    "pltl_wf.create_report_html(all_data, all_banches, path_to_work_dir  + \n",
    "                      dir_name_with_calculated_data + well_name + '_prediction_report.html',  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data_path = preproc_tool.find_full_path_by_pattern(os.getcwd(), '*static_data.xlsx*')\n",
    "static_data = workflow_tr_data.Static_data()\n",
    "static_data_df = pd.read_excel(static_data_path[0])\n",
    "static_data = workflow_tr_data.fill_static_data_structure_by_df(static_data, static_data_df, well_name + \" (ready)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unifloc_vba.description_generated.python_api as python_api\n",
    "path_to_addin = os.getcwd()\n",
    "path_to_addin = path_to_addin.replace('unifloc\\\\sandbox\\\\uTools', 'unifloc_vba\\\\UniflocVBA_7.xlam')\n",
    "UniflocVBA = python_api.API(path_to_addin)\n",
    "esp_traces = pltl_wf.create_esp_traces(UniflocVBA, static_data.esp_nom_rate_m3day, static_data.esp_nom_head_m, static_data.esp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp_df = all_data[[global_names.dp_esp_atm + \" (PREDICTION)\",\n",
    "          global_names.esp_head_m + \" (PREDICTION)\",\n",
    "          global_names.efficiency_esp_d + \" (PREDICTION)\",\n",
    "          global_names.q_mix_mean_m3day + \" (PREDICTION)\", \n",
    "          global_names.PowerESP_kwt + \" (PREDICTION)\", \n",
    "          global_names.gas_fraction_intake_d + \" (PREDICTION)\",\n",
    "          global_names.rs_intake_m3m3 + \" (PREDICTION)\",\n",
    "          global_names.c_calibr_head_d + \" (PREDICTION)\",\n",
    "          global_names.c_calibr_power_d + \" (PREDICTION)\"]]\n",
    "esp_df = esp_df.set_index(esp_df[global_names.q_mix_mean_m3day + \" (PREDICTION)\"])\n",
    "esp_df_traces = pltl_wf.create_traces_list_for_all_columms(esp_df, chosen_mode = 'markers', use_gl = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data_dimensionless = result_and_metrics.make_dimensionless_df(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path_to_work_dir + dir_name_with_calculated_data + well_name + '_dimless_pump_heatmap_report' + '.html'\n",
    "pltl_wf.create_overall_report(all_data, prediction_data_dimensionless, esp_traces, filename, esp_df_traces,  auto_open = auto_open_html,\n",
    "                             mark = \" (PREDICTION)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Сведение данных адаптации и восстановления\n",
    "Использование файлов типа `calc_and_input` в папках с адаптацией и восстновлением для формирования общего отчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_adapt_dir = 'adaptation_' + '\\\\'\n",
    "path_to_restore_dir = 'restore_' + '\\\\'\n",
    "dir_name_with_calculated_data = 'restore_' + '\\\\'\n",
    "calculated_data_file_name = well_name +'_restore_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка и слияние данных адаптации и восстановления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_data_with_input = pd.read_csv(path_to_work_dir + path_to_adapt_dir + well_name + '_calc_and_input' + '.csv' , parse_dates = True, index_col = 'Время')\n",
    "restore_data_with_input = pd.read_csv(path_to_work_dir + path_to_restore_dir + well_name + '_calc_and_input' + '.csv' , parse_dates = True, index_col = 'Время')\n",
    "overall_data = adapt_data_with_input.join(restore_data_with_input, how = 'outer', lsuffix = '', rsuffix = ' (PREDICT double)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заключительная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data = result_and_metrics.add_relative_errors_to_overall_data(overall_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка вывода в отчет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(report_type = 'overall_result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание сводного отчета `well_name_adapt_and_restore_report.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_traces = pltl_wf.create_traces_list_for_all_columms(overall_data, 'lines+markers', use_gl = True)\n",
    "plot_file_path = path_to_work_dir + dir_name_with_calculated_data + well_name + '_adapt_and_restore' +  '.html'\n",
    "pltl_wf.plot_subplots(input_data_traces, plot_file_path, True,  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_path = path_to_work_dir + path_to_restore_dir + well_name + '_adapt_and_restore_report' +  '.html'\n",
    "pltl_wf.create_report_html(overall_data, all_banches, plot_file_path,  auto_open = auto_open_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет различных метрик для модели и сохранение их в текстовый файл `well_name_adapt_and_restore_metrics_report.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result_and_metrics.make_result(overall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = path_to_work_dir + path_to_restore_dir + well_name + '_adapt_and_restore_metrics_report' +  '.xlsx'\n",
    "result.to_excel(result_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
