{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кобзарь Олег, Хабибуллин Ринат, Буденный Семен, Адрианова Алла, Логинов Александр, Лемихов Александр\n",
    "# Обработчик данных \n",
    "\n",
    "В данной тетрадке собраны все средства для работы с данными (пре- и пост- процессор; генерация входных данных для модели, анализ рассчитанных значений, построение графиков)\n",
    "\n",
    "Большое количество кода вынесено в модуле - здесь в основном управление\n",
    "\n",
    "`well_name` - номер исследуемой скважины, например `1`\n",
    "\n",
    "Исходными данные лежат в папке  `data` в папках, соответствующим названиям скважин. Это данные\n",
    "1. Со станции управления (`data/well_name/well_name.csv`). Большое количество записей, которые нужно преобразовать в \"шахмоткоподобный\" вид для дальнейшей работы. Данные со СУ могут быть как высокочастотными (токи, напряжения), так и низкочастотными. \n",
    "2. С шахматки `data/well_name/Скв. well_name (01.07.2018-31.03.2019).xls`. Низкочастотные данные. \n",
    "3. C техрежима `data/tr/Техрежим, , февраль 2019.xls`. Какой насос спущен, ПЭД, на какую глубину. Эти данные постоянны на всем периоде расчета. В одном файлике один месяц и данные для всех скважин.\n",
    "\n",
    "\n",
    "\n",
    "## Общий workflow\n",
    "Здесь кратко, подробное описание будет над ячейками.\n",
    "1. Обработка исходных данных со СУ и приведение их в удобный формат. (init_edit)\n",
    "2. Считавание подготовленных ранее данных со СУ, шахматки, а затем генерации входных данных для модели, конкретно, адаптации модели скважины за выбранный период времени. (adaptation_input)\n",
    "3. Адаптация. Теперь можно открыть файл processor.py и в нем, выставив настройки и определив входные данные, запустить расчет скважину. После адаптации данные появится данные с калибровочными коэффициентами. (adaptation)\n",
    "4. Считывание рассчитанных значений адаптации, данных со СУ и шахматки. Генерации файлов для восстановления дебитов (restore_input)\n",
    "5. Восстановление. Работа в processor.py, где необходимо изменить метод расчета и указать на новые входные данные. (restore) \n",
    "6. Заключительный анализ: сведение результатов адаптации и восстановления; расчет различных метрик для оценки метода (тоже в папке restore)\n",
    "\n",
    "По идее, если данные уже сгенерированы, каждый пункт может повторяться многократно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт модулей. Некоторые функции и методы вынесены в отдельные `.py`\n",
    "* `preprocessor` - для обработки данных в и из модели\n",
    "* `processor` - для непосредственного запуска расчета адаптации или восстановления\n",
    "* `postprocessor` - для завершающего анализа сгенерированных данных. Определение метрик успешности модели, паттернов, событий, зависимостей.\n",
    "* `plotly_workflow` - для быстрого построения шаблонизированных графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import pandas as pd\n",
    "import unifloc.uniflocpy.uTools.plotly_workflow as pw\n",
    "import datetime\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_workflow.plotly_option as pltl_opt\n",
    "import plot_workflow.plotly_workflow as pltl_wf\n",
    "\n",
    "from preproc_p import workflow_cs_data\n",
    "from preproc_p import workflow_chess_data\n",
    "from preproc_p import preproc_tool\n",
    "from preproc_p import workflow_calc_data\n",
    "from preproc_p import workflow_tr_data\n",
    "from preproc_p import filtration\n",
    "from proc_p import processor as proc\n",
    "\n",
    "from ml import calibr_restore as calibr_restore\n",
    "from postproc_p import result_and_metrics as result_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общие настройки и флаги для работы. Указание номера скважины и название файла шахматки. Флаги для запуска тех или иных ячеек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_name = '540'\n",
    "chess_file_name = 'Скв. ' + well_name + ' (01.08.2018-28.02.2019).xls'\n",
    "tr_name = \"Техрежим, , февраль 2019.xls\"\n",
    "# TODO убрать флаги\n",
    "read_initial_data = True\n",
    "plot_initial_data = True\n",
    "create_input_data = True\n",
    "multiprocessing_on = True #TODO может быть убрать флаги, как лучше?\n",
    "created_input_data_type = 0 # 0 - adaptation input, 1 - restore input with calibation coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение путей к данным. Создание метки времени к генерируемым папкам. (чтоб данные не перезаписывались)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "time_mark = '' #datetime.datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "path_to_data = current_path + \"\\\\data\\\\\"\n",
    "path_to_work_dir = current_path + \"\\\\data\\\\\" + well_name +  \"\\\\\"\n",
    "save_dir_name = 'init_edit'\n",
    "path_to_save = path_to_work_dir + save_dir_name + '\\\\'\n",
    "dirnames_list = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(path_to_data):\n",
    "    dirnames_list.extend(dirnames)\n",
    "    break\n",
    "print(dirnames_list)\n",
    "cs_data_filename = path_to_save + well_name + \"_first_edit.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание интервалов, на которых будет вестить расчет. Их может быть несколько. Рекомендуется поставить малый период времени, выявить ошибки, а затем запускать на месяцы и годы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_boundary = [datetime.datetime(2018,8,1), datetime.datetime(2018,11,29)]\n",
    "right_boundary = [datetime.datetime(2018,11,5), datetime.datetime(2019,2,28)]\n",
    "#left_boundary = [datetime.datetime(2018,8,3), datetime.datetime(2018,11,29),   datetime.datetime(2019,2,19)]\n",
    "#right_boundary = [datetime.datetime(2018,11,6), datetime.datetime(2019,2,4),  datetime.datetime(2019,2,28)]\n",
    "#left_boundary = [datetime.datetime(2019,1,30)]\n",
    "#right_boundary = [datetime.datetime(2019,2,28)]\n",
    "#left_boundary = [datetime.datetime(2018,8,1)]\n",
    "#right_boundary = [datetime.datetime(2018,12,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение функции которая все запустит в многопотоке и произведет из данного ноутбука адаптацию и восстановление. (Временный костыль - работает только здесь, в модуле не может)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_calculation(thread_option_list):\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(amount_of_threads) as p:\n",
    "            p.map(proc.calc,\n",
    "                  thread_option_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Обработка исходных данных\n",
    "Чтение исходных данных `well_name.csv` со СУ и преобразование их в удобный формат. Процесс небыстрый из-за несовершенства алгоритма форматирования и количества данных (около 1-1,5 млн. записей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if read_initial_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + save_dir_name)\n",
    "    except:\n",
    "        pass\n",
    "    well_data = workflow_cs_data.read_and_edit_init_cs_data(well_name, path_to_work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение обработанных данных со СУ в папку `init_edit`\n",
    "\n",
    "Процесс может быть долгим - 3 минуты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#TODO использовать библиотеку modin вместо pandas\n",
    "well_data.to_csv(path_to_save + well_name + \"_first_edit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков для нескольких интересующих параметров по исходным данных со СУ в `well_name__first_edit_report.html`. Процесс занимает около 3-5 минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "well_data['ГФ, м3/м3'] = well_data['Объемный дебит газа'] / well_data['Объемный дебит нефти']\n",
    "all_banches = pltl_opt.create_banches_for_report(well_data, report_type = 'init_cs_data')\n",
    "pw.create_report_html(well_data, all_banches, path_to_save + well_name + \"_first_edit_report.html\")\n",
    "del well_data['ГФ, м3/м3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение исходных данных с шахматки в `well_name_chess_report.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chess_data = workflow_chess_data.load_and_edit_chess_data(path_to_work_dir + chess_file_name,\n",
    "                                     '1d', without_changing = True) #TODO сделать протяжку вверх, для буферного давления\n",
    "\n",
    "\n",
    "all_banches = pltl_opt.create_banches_for_report(chess_data, report_type = 'init_chess_data')\n",
    "pw.create_report_html(chess_data, all_banches, path_to_save + well_name + \"_chess_report.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом этапе в папке init_edit окажутся\n",
    "1. well_name_init_edit.csv - данные с шахматки, которые будут подгружаться для адаптации и восстановления\n",
    "2. well_name_init_sp.html - график для исходных данных\n",
    "3.  well_name_init_edit_report.html - график для выбранных исходных данных\n",
    "\n",
    "Перейдем к следующему этапу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Генерация входных данных для адаптации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного этапа уже нужные обработанные данные со станции управления.\n",
    "\n",
    "Чтение исходных данных со СУ (в уже подготовленных). Обработка этих данных - ресемпл, пометка названий столбцов с помощью `(СУ)`. Т.к. данные высокочастотные, осредним их по 3 часам - примерному времени замера дебита скважины на АГЗУ. Обработка будет отличаться в зависимости от того, какие данные вы генерируете - для адаптации выбрасываются интервалы без замеров дебитов, для восстановления - нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_resamle = '3h'\n",
    "created_input_data_type = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "edited_data_cs = workflow_cs_data.load_and_edit_cs_data(cs_data_filename,\n",
    "                                       created_input_data_type,\n",
    "                                           time_to_resamle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем фильтрацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_data_cs = filtration.get_filtred_by_sigma(edited_data_cs) #TODO добавить сюда фильтрацию по времени замера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение данных с шахматки. Осреднение и протяжка параметров. Пометка названий столбцов маркером `(Ш)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chess_data = workflow_chess_data.load_and_edit_chess_data(path_to_work_dir + chess_file_name,\n",
    "                                     time_to_resamle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация входных данных для адаптации. Сведение данных с шахматки и со СУ. Создание папки с названием `adapt_input_` и временной пометкой и помещение в нее:\n",
    "* сгенерированных входных данных для модели `well_name_adapt_input.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir_name = 'adapt_input_' + time_mark\n",
    "path_to_input_data = path_to_work_dir + input_data_dir_name + '\\\\'\n",
    "if create_input_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + input_data_dir_name)\n",
    "    except:\n",
    "        pass\n",
    "created_input_data = edited_data_cs.join(chess_data, how = 'inner') #TODO протягивать буферное давление вверх\n",
    "created_input_data = created_input_data.dropna(subset = ['Объемный дебит жидкости (СУ)'])\n",
    "created_input_data = preproc_tool.cut_df(created_input_data, left_boundary, right_boundary)\n",
    "created_input_data = preproc_tool.check_input_data(created_input_data)\n",
    "created_input_data.to_csv(path_to_input_data + well_name + '_adapt_input.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все входные данные на графике `well_name_adapt_input.html` в той же папке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_path = path_to_input_data + well_name + '_adapt_input.html'\n",
    "input_data_traces = pw.create_traces_list_for_all_columms(created_input_data, 'lines+markers', use_gl = True)\n",
    "pw.plot_subplots(input_data_traces, plot_file_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение кривых в отчете только для тех данных, которые будут использоваться в модели в `well_name_adapt_input_report.html` в той же папке в стандартном виде. Можно настроить, какие данные выводить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(created_input_data, report_type = 'adapt_input')\n",
    "\n",
    "pw.create_report_html(created_input_data, all_banches, path_to_input_data + well_name + '_adapt_input_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Адаптация\n",
    "Нужно, используя сгенерированные данные `well_name_adapt_input` получить значения коэффициентов калибровок по напору и мощности с помощью `processor.py`\n",
    "\n",
    "Для этого выключить флаги\n",
    "\n",
    "* vfm_calc_option = False\n",
    "* restore_q_liq_only = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка к параллельному расчету.\n",
    "\n",
    "В проекте UniflocVBA нужно вручную размножить надстройки до нужного количества потоков - каждая надстройка будет работать параллельно и рассчитывать определенную часть общих данных. \n",
    "\n",
    "По умолчанию выставлено 4 потока на 4 надстройках `UniflocVBA_7.xlam`, `UniflocVBA_7_1.xlam`, `UniflocVBA_7_2.xlam`, `UniflocVBA_7_3.xlam`. При желании можно добавить еще, не забыв изменить также номера потоков и их общее количество.\n",
    "\n",
    "Группировка информации о потоках в единый список `thread_option_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка многопоточности\n",
    "amount_of_threads = 12\n",
    "tr_name = \"Техрежим, , февраль 2019.xls\"\n",
    "dir_name_with_input_data = 'adapt_input_'\n",
    "\n",
    "thread_option_list =proc.create_thread_list(well_name, dir_name_with_input_data, tr_name,\n",
    "                       amount_of_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск процесса адаптации - получения калибровок. Процесс может быть долгим - в среднем расчет идет медленнее, чем при восстановлении дебитов. \n",
    "\n",
    "Рассчет 1 месяца в среднем занимает около 15-20 минут.\n",
    "\n",
    "Стоит отметить, что для аварийного выхода нужно вручную закрыть надстройки Excel (окна, которые открыты и в них ведется работа). После закрытия всех четырех процесс остановится и возникнет ошибка, контроль над jupyter notebook вернется и можно будет работать.\n",
    "\n",
    "Поэтому для тщательной отладки `processor.py` рекомендуется запускать отдельно (лучше через PyCharm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_calculation(thread_option_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Генерация данных для восстановления дебитов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Загрузка и анализ адаптации\n",
    "После успешной адаптации нужно проанализировать ее корректность, построив графики. Для этого нужно указать директории с \n",
    "* результатами адапатации - `adaptation_time_mark`  \n",
    "* входными данными для адаптации - `adaptation_input_time_mark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_with_input_data = 'adapt_input_' + '\\\\'\n",
    "input_data_file_name = well_name + '_adapt_input'\n",
    "dir_name_with_calculated_data = 'adaptation_' + '\\\\'\n",
    "calculated_data_file_name = well_name + '_adapt_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если расчет проводился в многопоточном варианте, то загрузка будет отличаться. В папке с расчетами `adaptation` в сабдиректории `multiprocessing` будут результаты по частям в разных файликах, поэтому их нужно собрать в один файлик и поместить на уровень выше в `adaptation`. Если расчет был без использования многопоточности, этот шаг можно пропустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multiprocessing_on == True:\n",
    "    first_result_data = preproc_tool.combine_multiprocessing_result(path_to_work_dir, dir_name_with_calculated_data)\n",
    "    first_result_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + calculated_data_file_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных адаптации после расчета - в папке `adaptation_time_mark`  файл `well_name_adapt_1.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data = workflow_calc_data.load_calculated_data_from_csv(path_to_work_dir + dir_name_with_calculated_data +\n",
    "                                                calculated_data_file_name +  '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение входных данных для адаптации из папки `adaptation_input` и объединение данных адатации и входных данных для нее.\n",
    "Сохранение всех данных в папке `adaptation_time_mark` с названием `well_name_calc_and_input.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(path_to_work_dir + dir_name_with_input_data + input_data_file_name +  '.csv')\n",
    "input_data.index = input_data['Время']\n",
    "del input_data['Время']\n",
    "all_data = input_data.join(calculated_data, how = 'outer')\n",
    "\n",
    "all_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков для данных адаптации в папке  `adaptation_time_mark`\n",
    "\n",
    "Все данные (входные и результаты) на одном графике `well_name_calc_and_input.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_data_traces = pw.create_traces_list_for_all_columms(all_data, 'lines+markers', use_gl = True)\n",
    "plot_file_path = path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.html'\n",
    "pw.plot_subplots(adapt_data_traces, plot_file_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание отчета - набор нужных графиков для быстрой оценки результатов адаптации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(all_data, report_type = 'adapt_report')\n",
    "\n",
    "pw.create_report_html(all_data, all_banches, path_to_work_dir + dir_name_with_calculated_data + \n",
    "                      well_name + '_adapt_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Генерации данных для восстановления дебитов\n",
    "Работа с калибровками для восстановления дебитов. Для преобразования их выделим в отдельный DataFrame. Будем интерполировать, выкалавать точки, либо еще что-нибудь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_data = calculated_data[['К. калибровки по напору - множитель (Модель)',\n",
    "                               'К. калибровки по мощности - множитель (Модель)']]\n",
    "calibr_data = preproc_tool.mark_df_columns(calibr_data, 'Подготовленные')\n",
    "#calibr_data = calibr_data.resample('3h').mean()\n",
    "#calibr_data = calibr_data.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_out_lol, f_out_lol = calibr_restore.restore_calibr_via_ridge(all_data, calibr_data, use_80_20 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_resamle = '3h'\n",
    "created_input_data_type = 1 # костыль для 252 и 693 скважины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO учесть вариант, при котором калибровки линейно интерполируются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_data_cs = workflow_cs_data.load_and_edit_cs_data(cs_data_filename,created_input_data_type,\n",
    "                                       time_to_resamle\n",
    "                                       )\n",
    "chess_data = workflow_chess_data.load_and_edit_chess_data(path_to_work_dir + chess_file_name,\n",
    "                                     time_to_resamle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прозведем фильтрацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_data_cs = filtration.get_filtred_by_sigma(edited_data_cs) #TODO добавить сюда фильтрацию по времени замера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = preproc_tool.make_gaps_and_interpolate(calibr_data)\n",
    "calibr_data = result.copy()\n",
    "#all_data = all_data.join(calibr_data, how = 'inner')\n",
    "#created_input_data = all_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вставляем предсказания машины\n",
    "calibr_data['К. калибровки по мощности - множитель (Модель) (Подготовленные)'] = p_out_lol\n",
    "calibr_data['К. калибровки по напору - множитель (Модель) (Подготовленные)'] = f_out_lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для прогноза на хвосте обрежем данные, чтобы считать только прогнозные часть - 20% от всего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_data = calibr_data[calibr_data['К. калибровки по мощности - множитель (Модель) (Подготовленные)']!=\n",
    "                          calculated_data['К. калибровки по мощности - множитель (Модель)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем данные со СУ и шахматки и обработаем их, для генерации входных данных модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация входных данных для модели для восстановления дебитов в папку `restore_input_time_mark`\n",
    "* `well_name_restore_input.csv` - входные данных с калибровками (увеличили частоту дискретизации или выкололи точки)\n",
    "* `well_name_restore_input.html` - все входные данные на одном графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir_name = 'restore_input_' + time_mark\n",
    "path_to_input_data = path_to_work_dir + input_data_dir_name + '\\\\'\n",
    "if create_input_data:\n",
    "    try:\n",
    "        os.mkdir(path_to_work_dir + input_data_dir_name)\n",
    "    except:\n",
    "        pass\n",
    "created_input_data = edited_data_cs.join(chess_data, how = 'inner')\n",
    "created_input_data = created_input_data.join(calibr_data, how ='inner')\n",
    "created_input_data = preproc_tool.cut_df(created_input_data, left_boundary, right_boundary)\n",
    "created_input_data.to_csv(path_to_input_data + well_name + '_restore_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_path = path_to_input_data + well_name + '_restore_input.html'\n",
    "input_data_traces = pw.create_traces_list_for_all_columms(created_input_data, 'lines+markers', use_gl = True)\n",
    "pw.plot_subplots(input_data_traces, plot_file_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков в отчетной форме "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(created_input_data, report_type = 'restore_input')\n",
    "\n",
    "pw.create_report_html(created_input_data, all_banches, path_to_input_data  + \n",
    "                      well_name + '_restore_input_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Восстановление дебитов.\n",
    "Нужно, используя сгенерированные данные `well_name_restore_input` восстановить дебиты с помощью `postprocessor.py`\n",
    "Для этого активировать флаги\n",
    "* vfm_calc_option = True\n",
    "* restore_q_liq_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка к параллельному расчету.\n",
    "\n",
    "В проекте UniflocVBA нужно вручную размножить надстройки до нужного количества потоков - каждая надстройка будет работать параллельно и рассчитывать определенную часть общих данных. \n",
    "\n",
    "По умолчанию выставлено 4 потока на 4 надстройках `UniflocVBA_7.xlam`, `UniflocVBA_7_1.xlam`, `UniflocVBA_7_2.xlam`, `UniflocVBA_7_3.xlam`. При желании можно добавить еще, не забыв изменить также номера потоков и их общее количество.\n",
    "\n",
    "Группировка информации о потоках в единый список `thread_option_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка многопоточности\n",
    "\n",
    "amount_of_threads = 12\n",
    "tr_name = \"Техрежим, , февраль 2019.xls\"\n",
    "dir_name_with_input_data = 'restore_input_'\n",
    "\n",
    "thread_option_list =proc.create_thread_list(well_name, dir_name_with_input_data, tr_name,\n",
    "                       amount_of_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск процесса восстановления дебитов. Процесс может быть долгим - в среднем расчет восстановления дебитов идет быстрее, чем при адаптации (получении калибровок). \n",
    "\n",
    "Рассчет 1 месяца в среднем занимает около 10-15 минут.\n",
    "\n",
    "Стоит отметить, что для аварийного выхода нужно вручную закрыть надстройки Excel (окна, которые открыты и в них ведется работа). После закрытия всех четырех процесс остановится и возникнет ошибка, контроль над jupyter notebook вернется и можно будет работать.\n",
    "\n",
    "Поэтому для тщательной отладки processor.py рекомендуется его запускать отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_calculation(thread_option_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты расчета появятся в `well_name/restore_time_mark/multiprocessing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Работа с данными после восстановления дебитов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Первичная обработка результатов восстановления\n",
    "Обозначим директории с результатами восстановления дебитов и входными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_with_input_data = 'restore_input_' + '\\\\'\n",
    "input_data_file_name = well_name +'_restore_input'\n",
    "dir_name_with_calculated_data = 'restore_' + '\\\\'\n",
    "calculated_data_file_name = well_name +'_restore_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение данных при запуске расчета в многопотоке. Если расчет проводился без многопоточности, этот шаг можно пропустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multiprocessing_on == True:\n",
    "    first_result_data = preproc_tool.combine_multiprocessing_result(path_to_work_dir, dir_name_with_calculated_data)\n",
    "    first_result_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + calculated_data_file_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных после восстановления дебитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data = workflow_calc_data.load_calculated_data_from_csv(path_to_work_dir + dir_name_with_calculated_data +\n",
    "                                                calculated_data_file_name +  '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение входных и выходных данным модели. Сохранение результатов в `well_name_calc_and_input.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(path_to_work_dir + dir_name_with_input_data + input_data_file_name +  '.csv', parse_dates = True, index_col = 'Время')\n",
    "all_data = input_data.join(calculated_data, how = 'outer')\n",
    "all_data.to_csv(path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков восстановления дебитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_traces = pw.create_traces_list_for_all_columms(all_data, 'lines+markers', use_gl = True)\n",
    "plot_file_path = path_to_work_dir + dir_name_with_calculated_data + well_name + '_calc_and_input' +  '.html'\n",
    "pw.plot_subplots(input_data_traces, plot_file_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Сведение данных адаптации и восстановления\n",
    "Использование файлов типа `calc_and_input` в папках с адаптацией и восстновлением для формирования общего отчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_adapt_dir = 'adaptation_' + '\\\\'\n",
    "path_to_restore_dir = 'restore_' + '\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка и слияние данных адаптации и восстановления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_data_with_input = pd.read_csv(path_to_work_dir + path_to_adapt_dir + well_name + '_calc_and_input' + '.csv' , parse_dates = True, index_col = 'Время')\n",
    "adapt_data_with_input = preproc_tool.mark_df_columns(adapt_data_with_input, 'ADAPT')\n",
    "restore_data_with_input = pd.read_csv(path_to_work_dir + path_to_restore_dir + well_name + '_calc_and_input' + '.csv' , parse_dates = True, index_col = 'Время')\n",
    "restore_data_with_input = preproc_tool.mark_df_columns(restore_data_with_input, 'RESTORE')\n",
    "overall_data = adapt_data_with_input.join(restore_data_with_input, how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение дебитов методом линейной интерполяции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_liq = overall_data[['Объемный дебит жидкости (СУ) (ADAPT)', 'Активная мощность (СУ) (ADAPT)']]\n",
    "result = preproc_tool.make_gaps_and_interpolate(q_liq)\n",
    "result = preproc_tool.mark_df_columns(result, 'INTERP')\n",
    "overall_data = overall_data.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заключительная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data = result_and_metrics.final_edit_overall_data(overall_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка вывода в отчет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_banches = pltl_opt.create_banches_for_report(overall_data, report_type = 'overall_result')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание сводного отчета `well_name_adapt_and_restore_report.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_path = path_to_work_dir + path_to_restore_dir + well_name + '_adapt_and_restore_report' +  '.html'\n",
    "pw.create_report_html(overall_data, all_banches, plot_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет различных метрик для модели и сохранение их в текстовый файл `well_name_adapt_and_restore_metrics_report.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr_calc_metrics, interp_calc_metrics = result_and_metrics.calc_calibr_interp_metrics(overall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_text_file_path = path_to_work_dir + path_to_restore_dir + well_name + '_adapt_and_restore_metrics_report' +  '.txt'\n",
    "text_file = open(metrics_text_file_path, \"w\")\n",
    "text_file.write(calibr_calc_metrics + '\\n' + interp_calc_metrics)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Построение тепловой карты, характеристик и обезразмеренных величин\n",
    "Пару дополнительных функций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указание имени файла с техрежимов (при ошибке чтения его нужно открыть и закрыть)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_name = \"Техрежим, , февраль 2019.xls\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение данных с техрежима для данной скважины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_file_full_path = os.getcwd() + '\\\\data\\\\tr\\\\' + tr_name\n",
    "tr_data = workflow_tr_data.read_tr_and_get_data(tr_file_full_path, well_name)\n",
    "tr_data_df = pd.DataFrame({'Параметры скважины с ТР': list(tr_data.__dict__.values())})\n",
    "tr_data_df.index = list(tr_data.__dict__.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение метрик и данных по скважине в единый DataFrame (вместе с линейной интерполяцией). Сохранение в `_adapt_restore_metrics_tr_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_metrics = result_and_metrics.calc_calibr_interp_metrics(overall_data, return_df = True)\n",
    "\n",
    "overall_metrics['ЭЦН'] = [tr_data.esp_name_str, tr_data.esp_name_str]\n",
    "overall_metrics['ПЭД'] = [tr_data.motor_name_str, tr_data.motor_name_str]\n",
    "overall_metrics['Кол-во точек (ADAPT)'] = [len(overall_data['К. калибровки по напору - множитель (Модель) (ADAPT)']), \n",
    "                                           len(overall_data['К. калибровки по напору - множитель (Модель) (ADAPT)'])]\n",
    "\n",
    "overall_metrics.index = [well_name + ' (CALIBR)' , well_name + ' (INTERP)']\n",
    "overall_metrics.to_csv(path_to_work_dir + path_to_restore_dir + well_name + '_adapt_restore_metrics_tr_report' +  '.csv')\n",
    "overall_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вызов UniflocVBA и построение напорных характеристик (по воде) данного насоса, создание общего отчета с пометкой `_dimless_pump_heatmap_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_esp_nom_m3day = tr_data.esp_nom_rate_m3day\n",
    "head_esp_nom_m = tr_data.esp_nom_head_m\n",
    "\n",
    "import unifloc_vba.description_generated.python_api as python_api\n",
    "path_to_addin = os.getcwd()\n",
    "path_to_addin = path_to_addin.replace('unifloc\\\\sandbox\\\\uTools', 'unifloc_vba\\\\UniflocVBA_7.xlam')\n",
    "UniflocVBA = python_api.API(path_to_addin)\n",
    "esp_traces = pltl_wf.create_esp_traces(UniflocVBA, q_esp_nom_m3day, head_esp_nom_m)\n",
    "overall_data_dimensionless = result_and_metrics.make_dimensionless_df(overall_data)\n",
    "filename = path_to_work_dir + path_to_restore_dir + well_name + '_dimless_pump_heatmap_report' + '.html'\n",
    "pltl_wf.create_overall_report(overall_data, overall_data_dimensionless, esp_traces, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конец"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
