{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'E:\\Git')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preproc_p.preproc_tool as preproc_tool\n",
    "import preproc_p.workflow_cs_data as workflow_cs_data\n",
    "import plot_workflow.plotly_workflow as plotly_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preproc_p.workflow_periodic_wells as workflow_periodic_wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from multiprocessing import Pool\n",
    "import plot_workflow.plotly_option as pltl_opt\n",
    "import plot_workflow.plotly_workflow as pltl_wf\n",
    "\n",
    "from preproc_p import workflow_cs_data\n",
    "from preproc_p import workflow_chess_data\n",
    "from preproc_p import preproc_tool\n",
    "from preproc_p import workflow_calc_data\n",
    "from preproc_p import workflow_tr_data\n",
    "from preproc_p import filtration\n",
    "from preproc_p import workflow_periodic_wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gn = global_names = preproc_tool.GlobalNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг экселей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = preproc_tool.find_full_path_by_pattern(r'E:\\Данные\\2020_04_ноябрьск_су\\data_sort\\elr\\эксели_авто', \"*.*\",'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = r'E:\\Данные\\2020_04_ноябрьск_су\\data_sort\\elr\\эксели_авто\\csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#парсинг файликов\n",
    "for j, i in enumerate(files):\n",
    "    print(j)\n",
    "    try:\n",
    "        print(i)\n",
    "        this_file = workflow_cs_data.parse_cs_data_all_types(i)\n",
    "        new_file_name = path_to_save + '\\\\' + i.split('\\\\')[-1].replace('xls', 'csv')\n",
    "        this_file.to_csv(new_file_name)\n",
    "        print('\\n')\n",
    "    except:  \n",
    "        print('!!!!')\n",
    "        print(f\"Не распарсился файл {i}\")\n",
    "        print('!!!!')\n",
    "        print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_plot = preproc_tool.find_full_path_by_pattern(r'E:\\Данные\\2020_04_ноябрьск_су\\data_sort\\elr\\эксели_авто\\csv', '*.*','csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files_to_plot:\n",
    "    for j in files:\n",
    "        if i.split('\\\\')[-1].replace('.csv','') in j.split('\\\\')[-1]:\n",
    "            print(i)\n",
    "            this_df = pd.read_csv(i, index_col = [0], parse_dates = True)\n",
    "            #this_df.index = pd.to_datetime(this_df.index, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "            banches = plotly_workflow.create_banches_for_report(this_df, this_df.columns)\n",
    "            plotly_workflow.create_report_html(this_df, banches, i + '.html', auto_open = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ подготовленных данных .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = preproc_tool.find_full_path_by_pattern(r'E:\\Данные\\2020_04_ноябрьск_су\\dataset_to_use\\04_14_2020', \"*.*\",'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [ gn.q_liq_m3day, gn.q_oil_mass_tday, gn.q_gas_m3day,\n",
    "              gn.active_power_kwt, gn.i_a_motor_a, gn.motor_load_perc, gn.freq_hz, gn.cos_phi_d,\n",
    "             gn.p_intake_atm, gn.p_lin_atm, gn.t_intake_c, gn.t_motor_c,\n",
    "              gn.vibration_xy_msec2, gn.vibration_z_msec2,\n",
    "             \"Рабочая доля времени\", gn.work_status_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_cs_data(this_file_name):\n",
    "    \n",
    "        df = pd.read_csv(this_file_name, index_col = [0], parse_dates = True, dayfirst = True)\n",
    "        df = preproc_tool.rename_columns_by_dict(df)\n",
    "\n",
    "        gas_borders, gas_dfs, stats, df = workflow_periodic_wells.find_gas_periods(df, gn.i_a_motor_a)\n",
    "\n",
    "        stacks = workflow_periodic_wells.find_stucks(df)\n",
    "        stats['Количество перегрузок'] = len(stacks)\n",
    "\n",
    "\n",
    "        borders = [gas_borders, stacks]\n",
    "\n",
    "\n",
    "        banches = pltl_wf.create_banches_for_report(df, parameters, fuzzy_names=True)\n",
    "        new_file_name = this_file_name.replace('.csv', '.html')\n",
    "        new_file_name = new_file_name.replace('dataset_to_use', 'analysis_result')\n",
    "        print(' ---> ' + new_file_name +  '\\n')\n",
    "\n",
    "\n",
    "        table = pd.DataFrame(stats, index = [this_file_name.split('\\\\')[-1]])\n",
    "\n",
    "        table_for_plot = table.T\n",
    "        table_for_plot.index.name = 'Название исходного файла'\n",
    "\n",
    "        borders = [gas_borders, stacks]\n",
    "        pltl_wf.create_report_html(df, banches,new_file_name , borders = borders, auto_open=False, \n",
    "                                   df_for_table = table_for_plot)\n",
    "        return table\n",
    "\n",
    "\n",
    "    \n",
    "def save_result_excel(result_file, file_name):\n",
    "    new_file_name = file_name.replace('.csv', '.html')\n",
    "    new_file_name = new_file_name.replace('dataset_to_use', 'analysis_result')\n",
    "    excel_file_name = new_file_name\n",
    "    excel_file_name = excel_file_name.replace(new_file_name.split('\\\\')[-1], 'result_analysis.xlsx')\n",
    "    result_file.to_excel(excel_file_name)\n",
    "    print(excel_file_name)\n",
    "    \n",
    "def run_calculation(to_mp, func, amount_of_threads):\n",
    "    start_time = time.time()\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(amount_of_threads) as p:\n",
    "            result = p.map(func, to_mp)\n",
    "            \n",
    "    result_df  = None\n",
    "    for i,j in enumerate(result):\n",
    "        if i !=0 and type(j) != type(None):\n",
    "            result_df = result_df.append(j)\n",
    "        elif i ==0 and type(j) != type(None):\n",
    "            result_df = j.copy()\n",
    "        else:\n",
    "            pass\n",
    "    end_time = time.time()\n",
    "    print(f\"Затрачено времени {(end_time-start_time)/60} минут\")\n",
    "    return result_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = None\n",
    "for k, this_file_name in enumerate(files[:2]):\n",
    "    print(this_file_name)\n",
    "    \n",
    "    table = analyse_cs_data(this_file_name)\n",
    "    if k != 0:\n",
    "        result_file = result_file.append(table)\n",
    "    else:\n",
    "        result_file = table.copy()\n",
    "\n",
    "\n",
    "save_result_excel(result_file, files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = run_calculation(files, workflow_periodic_wells.analyse_cs_data, 10)\n",
    "save_result_excel(result_df, files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
