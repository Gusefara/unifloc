{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import prepro_options as opt\n",
    "import preprocessor as prep\n",
    "import postprocessor as postp\n",
    "import processor as proc\n",
    "import pandas as pd\n",
    "import unifloc.uniflocpy.uTools.plotly_workflow as pw\n",
    "import datetime\n",
    "from sklearn import metrics\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_name = 570\n",
    "mark = ''\n",
    "left_boundary = opt.get_left_bound(well_name)\n",
    "right_boundary = opt.get_rigth_bound(well_name)\n",
    "\n",
    "path_to_work_dir = f'data/{well_name}/restore_/'\n",
    "chess_file_name = f'Скв. {well_name} ({opt.get_total_well_interval(well_name)}).xls'\n",
    "cs_data_filename = f'data/{well_name}/init_edit/{well_name}_first_edit.csv'\n",
    "create_input_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Восстановление дебитов.\n",
    "Нужно, используя сгенерированные данные `well_name_restore_input` восстановить дебиты с помощью `postprocessor.py`\n",
    "Для этого активировать флаги\n",
    "* vfm_calc_option = True\n",
    "* restore_q_liq_only = True\n",
    "\n",
    "и определить папку с входными данными `dir_name_with_input_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_with_input_data = 'restore_input_' + '\\\\'\n",
    "input_data_file_name = f'{well_name}_restore_input'\n",
    "dir_name_with_calculated_data = 'restore_' + '\\\\'\n",
    "calculated_data_file_name = f'{well_name}_restore_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing_on = True\n",
    "if multiprocessing_on == True:\n",
    "    filenames_list = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path_to_work_dir + 'multiprocessing\\\\'):\n",
    "        filenames_list.extend(filenames)\n",
    "        break\n",
    "    print(filenames_list)\n",
    "    for i,j in enumerate(filenames_list):\n",
    "        if i == 0:\n",
    "            first_result_data = pd.read_csv(path_to_work_dir + 'multiprocessing\\\\' + j , parse_dates = True, index_col = 'Время')\n",
    "        else:\n",
    "            another_result_data = pd.read_csv(path_to_work_dir + 'multiprocessing\\\\' + j , parse_dates = True, index_col = 'Время')\n",
    "            first_result_data = first_result_data.append(another_result_data, sort = True)\n",
    "            del first_result_data['d']\n",
    "            first_result_data = first_result_data.dropna(subset = ['ESP.ESPpump.EffiencyESP_d'])\n",
    "    first_result_data.to_csv(f'data/{well_name}/restore_/{well_name}_restore_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных после восстановления дебитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_data = prep.load_calculated_data_from_csv(f'data/{well_name}/restore_{mark}/{well_name}_restore_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение входных и выходных данным модели. Сохранение результатов в `well_name_calc_and_input.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(f'data/{well_name}/restore_input/{well_name}_restore_input.csv',\n",
    "                         parse_dates=True, index_col = 'Время')\n",
    "all_data = input_data.join(calculated_data, how = 'outer')\n",
    "all_data.to_csv(f'data/{well_name}/restore_/{well_name}_calc_and_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков восстановления дебитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_data.index, all_data['Q ж, м3/сут (Модель)'].values - all_data['Объемный дебит жидкости (СУ)'].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Так, теперь погнали избавимся от выбросов\n",
    "Судя по всему фильтрация до запуска `processor.py` приводит к каким-то ошибкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_data['Объемный дебит жидкости (СУ)'], all_data['Время замера фактическое (СУ)'])\n",
    "plt.xlabel('Дебит')\n",
    "plt.ylabel('Время замера')\n",
    "plt.title(f'Well {well_name}')\n",
    "plt.show()\n",
    "print(len(all_data['Объемный дебит жидкости (СУ)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока-что выставим ручками значение \"ошибочного замера\"\n",
    "\n",
    "Здесь даже короткий замер не приводит к аномальным значениям дебита, но лучше бы его убрать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data['Время замера фактическое (СУ)'] >= 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, очень важно, чтобы аномальные точки, как например `09.09.18` в скважине `570` обязательно попали на обучение. Таким образом система поймёт важность, как в описанном случае, `ГФ`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь настроим регрессию на половине данных - через одну точку, начиная с первой и потестим её на второй половине\n",
    "\n",
    "Все данные нам не нужны, отбросим очевидно бесполезные ручками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_data[['ГФ (СУ)',\n",
    "              'Процент обводненности (СУ)',\n",
    "              'Давление на приеме насоса (пласт. жидкость) (СУ)',\n",
    "              'Рбуф (Ш)', 'Температура на приеме насоса (пласт. жидкость) (СУ)',\n",
    "              'F вращ ТМ (Ш)', 'Dшт (Ш)',\n",
    "              'Активная мощность (СУ)',\n",
    "              'Напряжение на выходе ТМПН (СУ)',\n",
    "              'Коэффициент мощности (СУ)',\n",
    "              'Объемный дебит жидкости (СУ)',\n",
    "              'Q ж, м3/сут (Модель)',\n",
    "              'F вращ ТМ (Ш)'\n",
    "             ]\n",
    "            ].copy()\n",
    "\n",
    "\n",
    "print(f'number of NaN values: {np.isnan(x.values).sum()}/{x.shape[0]}')\n",
    "x.dropna(inplace=True)\n",
    "data = x.dropna()\n",
    "\n",
    "y = pd.Series(x['Объемный дебит жидкости (СУ)'].values - x['Q ж, м3/сут (Модель)'].values)\n",
    "x.drop(columns=['Объемный дебит жидкости (СУ)', 'Q ж, м3/сут (Модель)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train_drop_2_points(data: pd.DataFrame, target: pd.Series):\n",
    "    out_x_train = data[data.index % 2 == 0]\n",
    "    out_y_train = target[target.index % 2 == 0]\n",
    "    out_x_test = data[data.index % 2 == 1]\n",
    "    out_y_test = target[target.index % 2 == 1]\n",
    "    return out_x_train, out_x_test, out_y_train, out_y_test\n",
    "\n",
    "def get_joined_2_points_target(y_test, y_train):\n",
    "    out = [None] * (len(y_test) + len(y_train))\n",
    "    y_test = list(y_test)\n",
    "    y_train = list(y_train)\n",
    "    for i in range(len(out)):\n",
    "        if i % 2 == 0:\n",
    "            out[i] = y_train[int(i/2)]\n",
    "        else:\n",
    "            out[i] = y_test[int((i-1)/2)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = x.index\n",
    "x.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_test_train_drop_2_points(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.values.reshape((-1, 1))\n",
    "y_train = y_train.values.reshape((-1, 1))\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "\n",
    "sc_y = StandardScaler()\n",
    "sc_y.fit(y_train)\n",
    "\n",
    "x_train_sc = sc_x.transform(x_train)\n",
    "x_test_sc = sc_x.transform(x_test)\n",
    "\n",
    "y_train_sc = sc_y.transform(y_train)\n",
    "y_test_sc = sc_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha': np.linspace(1e-7, 30, 1000)}\n",
    "\n",
    "r_est = linear_model.Ridge()\n",
    "gs_cv = GridSearchCV(r_est, parameters, cv=7)\n",
    "_ = gs_cv.fit(x_train_sc, y_train_sc)\n",
    "b_r_est = gs_cv.best_estimator_\n",
    "predicted_err = sc_y.inverse_transform(b_r_est.predict(sc_x.transform(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(date_col, predicted_err[:, 0] + data['Q ж, м3/сут (Модель)'].values, label='predicted')\n",
    "plt.plot(date_col, data['Объемный дебит жидкости (СУ)'], label='y_true')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.24, 0.8))\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('q_liq, m3/day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде нормал, посчитаем `mae`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = metrics.mean_absolute_error(predicted_err[:, 0] + data[\"Q ж, м3/сут (Модель)\"].values,\n",
    "                                  data[\"Объемный дебит жидкости (СУ)\"])\n",
    "print(f'MAE_score: {err}')\n",
    "print(f'MAE_score as %: {err/data[\"Объемный дебит жидкости (СУ)\"].mean() * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на ошибки на обучении/тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_err_test = b_r_est.predict(x_test_sc)\n",
    "print(f'MAE test,  scaled err = {metrics.mean_absolute_error(y_test_sc, predicted_err_test)}')\n",
    "predicted_err_train = b_r_est.predict(x_train_sc)\n",
    "print(f'MAE train, scaled err = {metrics.mean_absolute_error(y_train_sc, predicted_err_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# хммм, 15% это не так плохо\n",
    "## посмотрим на \"интегральную ошибку\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integrted_data(y: list, date, crit_time_delta=datetime.timedelta(2, 0 * 60 * 60*12 )):\n",
    "    out = 0\n",
    "    if len(date) != len(y):\n",
    "        print('not the same length')\n",
    "        return -1\n",
    "    for i in range(len(date)-1):\n",
    "        if date[i + 1]- date[i] <=  crit_time_delta:\n",
    "            out += 0.5 * (y[i] + y[i+1])\n",
    "        else:\n",
    "            pass# print(f'long time no data, {date[i]} - {date[i+1]}')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_0 = get_integrted_data(predicted_err[:, 0] + data[\"Q ж, м3/сут (Модель)\"].values, date_col)\n",
    "int_err = int_0 - get_integrted_data( data[\"Объемный дебит жидкости (СУ)\"].values, date_col)\n",
    "print(f'integrated error = {abs(int_err)/int_0 * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем улучшить\n",
    "Сейчас есть скачёк вниз, котрый, возможно, обусловленн `ГФ(СУ)`. А может это просто плохой замер\n",
    "\n",
    "При этом, почти совсем нет реакции на эту точку.\n",
    "\n",
    "Хотелось бы подобарть признак, который отловит этот скачок.\n",
    "\n",
    "1. Посмотрим, что будет, если просто размножить эту точку\n",
    "\n",
    "- Всё-таки посмотрим на корреляции и важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = all_data['Объемный дебит жидкости (СУ)'].mean()\n",
    "sig = np.sqrt(all_data['Объемный дебит жидкости (СУ)'].var())\n",
    "mh_train = all_data[np.abs(all_data['Объемный дебит жидкости (СУ)'] - m) > 3 * sig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настакиваем аномальные точки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_train = mh_train[['ГФ (СУ)', 'Процент обводненности (СУ)', 'Давление на приеме насоса (пласт. жидкость) (СУ)',\n",
    "                  'Рбуф (Ш)', 'Температура на приеме насоса (пласт. жидкость) (СУ)', 'F вращ ТМ (Ш)', 'Dшт (Ш)',\n",
    "                  'Активная мощность (СУ)', 'Напряжение на выходе ТМПН (СУ)', 'Коэффициент мощности (СУ)',\n",
    "                  'Объемный дебит жидкости (СУ)', 'Q ж, м3/сут (Модель)', 'F вращ ТМ (Ш)']\n",
    "                 ]\n",
    "\n",
    "x_train_ap = mh_train.drop(columns=['Объемный дебит жидкости (СУ)', 'Q ж, м3/сут (Модель)'])\n",
    "x_train_ap.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y_train_ap = pd.Series(mh_train['Объемный дебит жидкости (СУ)'].values - mh_train['Q ж, м3/сут (Модель)'].values)\n",
    "y_train_ap.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "for i in range(7):\n",
    "    x_train = x_train.append(x_train_ap)\n",
    "    y_train = np.append(y_train, y_train_ap.values.reshape((-1, 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "\n",
    "sc_y = StandardScaler()\n",
    "sc_y.fit(y_train)\n",
    "\n",
    "x_train_sc = sc_x.transform(x_train)\n",
    "x_test_sc = sc_x.transform(x_test)\n",
    "\n",
    "y_train_sc = sc_y.transform(y_train)\n",
    "y_test_sc = sc_y.transform(y_test)\n",
    "\n",
    "parameters = {'alpha': np.linspace(1e-7, 30, 1000)}\n",
    "\n",
    "r_est = linear_model.Ridge()\n",
    "gs_cv = GridSearchCV(r_est, parameters, cv=7)\n",
    "_ = gs_cv.fit(x_train_sc, y_train_sc)\n",
    "b_r_est = gs_cv.best_estimator_\n",
    "predicted_err = sc_y.inverse_transform(b_r_est.predict(sc_x.transform(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(date_col, predicted_err[:, 0] + data['Q ж, м3/сут (Модель)'].values, label='predicted')\n",
    "plt.plot(date_col, data['Объемный дебит жидкости (СУ)'], label='y_true')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.24, 0.8))\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('q_liq, m3/day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = metrics.mean_absolute_error(predicted_err[:, 0] + data[\"Q ж, м3/сут (Модель)\"].values,\n",
    "                                  data[\"Объемный дебит жидкости (СУ)\"])\n",
    "print(f'MAE_score: {err}')\n",
    "print(f'MAE_score as %: {err/data[\"Объемный дебит жидкости (СУ)\"].mean() * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде бы `MAE` увеличилась, а ошибка за интерграл - уменьшилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = get_test_train_drop_2_points(x, y)\n",
    "\n",
    "y_test = y_test.values.reshape((-1, 1))\n",
    "y_train = y_train.values.reshape((-1, 1))\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "\n",
    "sc_y = StandardScaler()\n",
    "sc_y.fit(y_train)\n",
    "\n",
    "x_train_sc = sc_x.transform(x_train)\n",
    "x_test_sc = sc_x.transform(x_test)\n",
    "\n",
    "y_train_sc = sc_y.transform(y_train)\n",
    "y_test_sc = sc_y.transform(y_test)\n",
    "\n",
    "predicted_err = sc_y.inverse_transform(b_r_est.predict(sc_x.transform(x)))\n",
    "\n",
    "int_0 = get_integrted_data(predicted_err[:, 0] + data[\"Q ж, м3/сут (Модель)\"].values, date_col)\n",
    "int_err = int_0 - get_integrted_data( data[\"Объемный дебит жидкости (СУ)\"].values, date_col)\n",
    "print(f'integrated error = {abs(int_err)/int_0 * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Всё-таки посмотрим на корреляции и важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_corr = all_data[['ГФ (СУ)', 'Процент обводненности (СУ)', 'Давление на приеме насоса (пласт. жидкость) (СУ)',\n",
    "                   'Рбуф (Ш)', 'Температура на приеме насоса (пласт. жидкость) (СУ)', 'F вращ ТМ (Ш)', 'Dшт (Ш)',\n",
    "                   'Активная мощность (СУ)', 'Напряжение на выходе ТМПН (СУ)', 'Коэффициент мощности (СУ)',\n",
    "                   'Объемный дебит жидкости (СУ)', 'F вращ ТМ (Ш)', 'Q ж, м3/сут (Модель)'\n",
    "                  ]].dropna()\n",
    "x_corr['ERROR'] = x_corr['Объемный дебит жидкости (СУ)'].values - x_corr['Q ж, м3/сут (Модель)'].values\n",
    "corr = x_corr.drop(columns=['Объемный дебит жидкости (СУ)', 'Q ж, м3/сут (Модель)', 'Dшт (Ш)']).corr()\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, линейной связи между `ГФ` и ошибкой нет. Чтож, видимо она не линейная.\n",
    "\n",
    "Вообще, судя по графикам, нас волнуют только лишь значительые изменения `ГФ`, мб попробовать перейти к `ln(ГФ)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_data[['ГФ (СУ)',\n",
    "              'Процент обводненности (СУ)',\n",
    "              'Давление на приеме насоса (пласт. жидкость) (СУ)',\n",
    "              'Рбуф (Ш)', 'Температура на приеме насоса (пласт. жидкость) (СУ)',\n",
    "              'F вращ ТМ (Ш)', 'Dшт (Ш)',\n",
    "              'Активная мощность (СУ)',\n",
    "              'Напряжение на выходе ТМПН (СУ)',\n",
    "              'Коэффициент мощности (СУ)',\n",
    "              'Объемный дебит жидкости (СУ)',\n",
    "              'Q ж, м3/сут (Модель)',\n",
    "              'F вращ ТМ (Ш)'\n",
    "             ]\n",
    "            ].copy()\n",
    "\n",
    "\n",
    "print(f'number of NaN values: {np.isnan(x.values).sum()}/{x.shape[0]}')\n",
    "x.dropna(inplace=True)\n",
    "data = x.dropna()\n",
    "    \n",
    "x['ГФ (СУ)'] = np.log(x['ГФ (СУ)'].values)\n",
    "x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "x.dropna(inplace=True)    \n",
    "y = pd.Series(x['Объемный дебит жидкости (СУ)'].values - x['Q ж, м3/сут (Модель)'].values)\n",
    "y_0 = x['Q ж, м3/сут (Модель)']\n",
    "y_0_true= x['Объемный дебит жидкости (СУ)']\n",
    "x.drop(columns=['Объемный дебит жидкости (СУ)', 'Q ж, м3/сут (Модель)'], inplace=True)\n",
    "date_col = x.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_test_train_drop_2_points(x, y)\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "\n",
    "sc_y = StandardScaler()\n",
    "sc_y.fit(y_train.values.reshape((-1, 1)))\n",
    "\n",
    "x_train_sc = sc_x.transform(x_train)\n",
    "x_test_sc = sc_x.transform(x_test)\n",
    "\n",
    "y_train_sc = sc_y.transform(y_train.values.reshape((-1, 1)))\n",
    "y_test_sc = sc_y.transform(y_test.values.reshape((-1, 1)))\n",
    "\n",
    "parameters = {'alpha': np.linspace(1e-7, 30, 1000)}\n",
    "\n",
    "r_est = linear_model.Ridge()\n",
    "gs_cv = GridSearchCV(r_est, parameters, cv=7)\n",
    "_ = gs_cv.fit(x_train_sc, y_train_sc)\n",
    "b_r_est = gs_cv.best_estimator_\n",
    "predicted_err = sc_y.inverse_transform(b_r_est.predict(sc_x.transform(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(date_col, y_0_true, label='y_true')\n",
    "plt.plot(date_col, predicted_err[:, 0] + y_0.values, label='predicted')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.24, 0.8))\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('q_liq, m3/day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = metrics.mean_absolute_error(predicted_err[:, 0] + y_0.values,\n",
    "                                  y_0_true)\n",
    "print(f'MAE_score: {err}')\n",
    "print(f'MAE_score as %: {err/y_0_true.mean() * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = get_test_train_drop_2_points(x, y)\n",
    "\n",
    "y_test = y_test.values.reshape((-1, 1))\n",
    "y_train = y_train.values.reshape((-1, 1))\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "\n",
    "sc_y = StandardScaler()\n",
    "sc_y.fit(y_train)\n",
    "\n",
    "x_train_sc = sc_x.transform(x_train)\n",
    "x_test_sc = sc_x.transform(x_test)\n",
    "\n",
    "y_train_sc = sc_y.transform(y_train)\n",
    "y_test_sc = sc_y.transform(y_test)\n",
    "\n",
    "predicted_err = sc_y.inverse_transform(b_r_est.predict(sc_x.transform(x)))\n",
    "\n",
    "int_0 = get_integrted_data(predicted_err[:, 0] + y_0.values, date_col)\n",
    "int_err = int_0 - get_integrted_data(y_0_true, date_col)\n",
    "print(f'integrated error = {abs(int_err)/int_0 * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять, видимо 2 метрики `MAE` и ошибка по интегралу - довольно разные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит просто каеф. Например, в скважине `693` есть несинхронные пики, ну а интеграл не сильно портится от того что они \n",
    "не синхронные\n",
    "\n",
    "Наверное всё-таки нужно построить что-то типа `_report`, попробуемсс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overall_data = all_data.dropna()\n",
    "overall_data['Q_l(ML error predicted)'] = predicted_err[:, 0] + data[\"Q ж, м3/сут (Модель)\"].values\n",
    "overall_data['Q_l error unifloc'] = overall_data['Объемный дебит жидкости (СУ)'].values-overall_data['Q ж, м3/сут (Модель)'].values\n",
    "overall_data['Q_l error (ML restored)'] = predicted_err[:, 0]\n",
    "overall_data.rename(columns={\"Q ж, м3/сут (Модель)\": 'Q_l pred unifloc(calibr = 1)', \n",
    "                             'Объемный дебит жидкости (СУ)': 'Q_l true'\n",
    "                            }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = {'Errors': ['Q_l error unifloc', 'Q_l error (ML restored)']}\n",
    "\n",
    "liquid_rates = {'Дебиты':  ['Q_l true', 'Q_l pred unifloc(calibr = 1)', 'Q_l(ML error predicted)']}\n",
    "\n",
    "essential_metrics = {'Обводнённость и ГФ': ['Процент обводненности (СУ)', 'ГФ (СУ)']}\n",
    "\n",
    "pressures = {'Давления': ['Давление на приеме насоса (пласт. жидкость) (СУ)','Рбуф (Ш)',\n",
    "             'Линейное давление (СУ)']}\n",
    "\n",
    "temperatures = {'Температуры': ['Температура на приеме насоса (пласт. жидкость) (СУ)', 'T прием ЭЦН, C (Модель)',\n",
    "                'T поверхности, С (Модель)', 'T выкид ЭЦН, С (Модель)', 'T прием, С  (Модель)', 'T устья, С (Модель)']\n",
    "               }\n",
    "\n",
    "power = {'Мощность': ['Активная мощность (СУ)', 'Мощность, передаваемая ЭЦН (Модель)',\n",
    "         'Мощность, передаваемая жидкости (Модель)','Мощность, передаваемая кабелю (Модель)', \n",
    "         'Мощность, потребляемая СУ (Модель)', 'Мощность, потребляемая газосепаратором (Модель)', \n",
    "         'Мощность, потребляемая протектором (Модель)', 'Мощность, потребляемая ТМПН (Модель)', \n",
    "         'Мощность, передаваемая СУ (Модель)', 'Мощность, передаваемая ПЭД (Модель)']\n",
    "        }\n",
    "\n",
    "load = {'Загрузка': ['Загрузка двигателя (Модель)']}\n",
    "\n",
    "all_banches = [liquid_rates, errors, essential_metrics, pressures, temperatures, power, load]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
